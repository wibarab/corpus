{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34c743a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ELAN to TEI conversion \n",
    "\n",
    "**Author:** Daniel Schopper    \n",
    "**Description:** This notebook automates the ELAN to TEI conversion in the WIBARAB Project. It is based on the same process in the SHAWI Project.\n",
    "**Last Change:** 2023-10-10     \n",
    "**History:**    \n",
    "* 2023-10-10: Initital set up\n",
    "* 2023-10-12: updated to Saxon CE HE (Omar Siam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c93b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sharepy\n",
    "import os\n",
    "import logging\n",
    "import requests\n",
    "import pathlib\n",
    "#import filetype â€“ not used\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit\n",
    "from lxml import isoschematron, etree\n",
    "import saxonche\n",
    "from zipfile import ZipFile\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "# from inspect import getmembers, signature\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd189fd",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600d7a8e-fa0d-4c83-afdb-7fcf3430c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the URL of the Sharepoint installation \n",
    "sp_baseURL = \"oeawacat.sharepoint.com\"\n",
    "\n",
    "# the sharepoint username + password are taken from the environment\n",
    "sp_username = os.environ['SP_USERNAME']\n",
    "sp_pwd = pwd = os.environ['SP_PWD']\n",
    "\n",
    "# the name of the Sharepoint Site\n",
    "sp_siteName = \"ACDH-CH_p_WIBARAB_BedoinTypeArabicNomadicSedentaryPeopleMidd\"\n",
    "\n",
    "# the path to the Excel file\n",
    "sp_pathToRecordingsXLSX = \"Shared%20Documents/Fieldwork%20data%20+%20analysis/WIBARAB_Recordings.xlsx\"\n",
    "\n",
    "\n",
    "# the name of the local directory where downloaded data will be stored\n",
    "dataDir = \"data\"\n",
    "\n",
    "# the name of the local directory where downloaded libraries and other auxiliary code will be stored\n",
    "libDir = \"lib\"\n",
    "\n",
    "# the root of the git repository\n",
    "dataHomeDir = \"../..\"\n",
    "\n",
    "# path to project-specific stylesheets\n",
    "pathToStylesheetsDir = dataHomeDir+\"/082_scripts_xsl\"\n",
    "\n",
    "# the path to the ELAN transcription files\n",
    "pathToELANDir = dataHomeDir+\"/122_elan\"\n",
    "\n",
    "# the path to the non-annotated TEI transcription files\n",
    "pathToTEIDir = dataHomeDir+\"/103_tei_w\"\n",
    "\n",
    "# the path to the annotated TEI transcription files\n",
    "pathToAnnotatedTEIDir = dataHomeDir+\"/010_manannot\"\n",
    "\n",
    "\n",
    "# the path to the NoSkE verticals\n",
    "noSkEVertDir = dataHomeDir+\"/130_vert_plain\"\n",
    "\n",
    "# the path to the tei Corpus document produced by this script\n",
    "pathToTeiCorpus = pathToTEIDir+\"/wibarabCorpus.xml\"\n",
    "\n",
    "\n",
    "# the path to the audio files\n",
    "pathToRecordingsDir = \"THIS_IS_NOT_USED\"#\"/mnt/univie_orientalistik/SHAWI/Recordings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88993602-1207-4906-9325-071e594b99b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:11,440 - SaxonC-HE 12.3 from Saxonica\n",
      "2023-10-23 10:53:11,441 - /home/dschopper/data/WIBARAB/corpus/080_scripts_generic\n",
      "2023-10-23 10:53:11,444 - ** setting up directories **\n",
      "2023-10-23 10:53:11,445 - skipped existing directory 'data'\n",
      "2023-10-23 10:53:11,446 - skipped existing directory 'lib'\n"
     ]
    }
   ],
   "source": [
    "with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "    logging.info(proc.version)\n",
    "    proc.set_cwd(os.path.dirname(os.path.abspath('')))\n",
    "    logging.info(proc.cwd)\n",
    "\n",
    "\n",
    "#set up directories\n",
    "logging.info(\"** setting up directories **\")\n",
    "for i in [dataDir,libDir]: \n",
    "    if os.path.exists(i):\n",
    "        logging.info(\"skipped existing directory '\"+i+\"'\")\n",
    "    else:\n",
    "        os.mkdir(i)\n",
    "        logging.info(\"created directory '\"+i+\"'\")\n",
    "        \n",
    "        \n",
    "# define which steps should be skipped. \n",
    "\n",
    "SKIP_PROCESSING = []#[\"runTEICorpo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda0dc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Step 1: get the latest release of the TEI Stylesheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5960d582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:11,463 - ** Fetching library TEIC/TEI **\n",
      "2023-10-23 10:53:12,112 - We have already the latest version (P5_Release_4.6.0). Exiting\n",
      "2023-10-23 10:53:12,118 - \n",
      "2023-10-23 10:53:12,130 - ** Fetching library TEIC/Stylesheets **\n",
      "2023-10-23 10:53:12,498 - We have already the latest version (v7.55.0). Exiting\n",
      "2023-10-23 10:53:12,501 - \n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "# fetch the TEI Stylesheets    \n",
    "def installFromGithub(libraryName):\n",
    "    auth = {}\n",
    "    if 'GITHUB_TOKEN' in os.environ:\n",
    "        auth = {\"Authorization\": \"Bearer \"+os.environ['GITHUB_TOKEN']}\n",
    "    headers = {\"Accept\" : \"application/vnd.github.v3+json\"}\n",
    "    repo = libraryName\n",
    "    logging.info(\"** Fetching library \"+repo+\" **\")\n",
    "    libBasePath = libDir+\"/\"+repo\n",
    "    \n",
    "    # First we check which tag name the latest release has\n",
    "    r = requests.get(\"https://api.github.com/repos/\"+repo+\"/releases/latest\", headers={**headers, **auth})\n",
    "    if r.status_code != 200:\n",
    "        logging.error(\"An error occured fetching the latest release. Maybe there isn't any release? \")\n",
    "        logging.error(r.content)\n",
    "        return 1\n",
    "    release = r.json()\n",
    "    tag = release[\"tag_name\"]\n",
    "    \n",
    "    # we check whether we have the latest version already \\\n",
    "    # by checking if the respective path is already installed\n",
    "    libReleasePath = libBasePath+\"/\"+tag\n",
    "    haveLatestVersion = os.path.exists(libReleasePath)\n",
    "    if haveLatestVersion:\n",
    "        logging.info(\"We have already the latest version (\"+tag+\"). Exiting\")\n",
    "        logging.info(\"\")\n",
    "        return libReleasePath\n",
    "    else:\n",
    "        url = release[\"assets\"][0][\"browser_download_url\"]\n",
    "        payload = requests.get(url, headers=auth).content\n",
    "        zipfilename = os.path.basename(url)\n",
    "        os.makedirs(libReleasePath, exist_ok=True)\n",
    "        zipfilePath = libReleasePath +\"/\"+zipfilename\n",
    "        open(zipfilePath, 'wb').write(payload)\n",
    "        ZipFile(zipfilePath).extractall(path=libReleasePath)\n",
    "        logging.info(\"Downloaded latest version (\"+tag+\") to \"+libReleasePath)\n",
    "        logging.info(\"\")\n",
    "        return libReleasePath\n",
    "\n",
    "\n",
    "pathToTEIGuidelines=installFromGithub(\"TEIC/TEI\")\n",
    "pathToTEIStylesheets=installFromGithub(\"TEIC/Stylesheets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c41966",
   "metadata": {},
   "source": [
    "### Step 2: Download the latest version of the Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842ce3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:12,539 - attempting to download file from 'https://oeawacat.sharepoint.com/sites/ACDH-CH_p_WIBARAB_BedoinTypeArabicNomadicSedentaryPeopleMidd/Shared%20Documents/Fieldwork%20data%20+%20analysis/WIBARAB_Recordings.xlsx'\n",
      "2023-10-23 10:53:17,129 - data/WIBARAB_Recordings.xlsx\n"
     ]
    }
   ],
   "source": [
    "# TODO will need to add credentials if this is run in non-interactive mode\n",
    "def downloadFromSP(sp_filepath, force=False):\n",
    "    url = \"https://\"+sp_baseURL+\"/sites/\"+sp_siteName+\"/\"+sp_filepath\n",
    "    logging.info(\"attempting to download file from '\"+url+\"'\")\n",
    "    filename = os.path.basename(sp_filepath)\n",
    "    downloadPath = dataDir+\"/\"+filename\n",
    "    if os.path.exists(downloadPath) and not force:\n",
    "        logging.info(\"skipping existing file \"+downloadPath)\n",
    "        return downloadPath\n",
    "    else:\n",
    "        s = sharepy.connect(sp_baseURL, username=sp_username, password=sp_pwd)\n",
    "        s.getfile(url, filename=downloadPath)\n",
    "        return downloadPath\n",
    "\n",
    "\n",
    "pathToExcelSheet = downloadFromSP(sp_pathToRecordingsXLSX, force=\"downloadExcelSheet\" not in SKIP_PROCESSING)\n",
    "logging.info(pathToExcelSheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9687813",
   "metadata": {},
   "source": [
    "## Step 2: transform xlsx to TEI table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c1a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(s, xsl, o, parameters=[]):\n",
    "    # processor keeps files open on Windows and in doing so prevents moving or copying them\n",
    "    with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "        proc.set_configuration_property(\"xi\", \"on\")\n",
    "        saxon = proc.new_xslt30_processor()\n",
    "        for i in parameters:\n",
    "            saxon.set_parameter(name=i, value=proc.make_string_value(parameters[i]))\n",
    "        try:\n",
    "            exec = saxon.compile_stylesheet(stylesheet_file=os.path.abspath(xsl))\n",
    "            exec.set_global_context_item(file_name=os.path.abspath(s))\n",
    "            # From the docs saxonc.html#PyXsltExecutable-set_initial_match_selection\n",
    "            # This method does not set the global context item for the transformation;\n",
    "            # if that is required, it can be done separately using the set_global_context_item method.\n",
    "            exec.apply_templates_returning_file(source_file=os.path.abspath(s), output_file=os.path.abspath(o))\n",
    "        except saxonche.PySaxonApiError as e:\n",
    "            logging.info(str(e))\n",
    "            logging.info(os.path.abspath(s)+\" - \"+os.path.abspath(xsl)+\" -> \"+os.path.abspath(o)+\" failed\")\n",
    "        if proc.exception_occurred:\n",
    "            logging.info(proc.get_error_message())\n",
    "            logging.info(os.path.abspath(s)+\" - \"+os.path.abspath(xsl)+\" -> \"+os.path.abspath(o)+\" failed\")\n",
    "        if os.path.exists(os.path.abspath(o)):\n",
    "            return o\n",
    "        else: \n",
    "            logging.info(\"there was an error transforming \"+s+\" with stylesheet \"+xsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531fda65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xlsx2teitable(xlsx, output):\n",
    "\n",
    "    # first, extract contents of XLSX document to a temp directory\n",
    "    unzipPath=xlsx.replace(\".xlsx\",\"\")\n",
    "    os.makedirs(unzipPath, exist_ok=True)\n",
    "    ZipFile(xlsx).extractall(path=unzipPath)\n",
    "    \n",
    "    # then transform the .rels file using the TEIC Stylesheets \n",
    "    pathToXlsxtoteiXSL=pathToTEIStylesheets+\"/xml/tei/stylesheet/xlsx/xlsxtotei.xsl\"\n",
    "\n",
    "    params = {\n",
    "        \"inputDir\" : pathlib.Path(os.path.abspath(unzipPath)).as_uri(),\n",
    "        \"workDir\" : pathlib.Path(os.path.abspath(unzipPath)).as_uri()\n",
    "    }\n",
    "\n",
    "    transform(\n",
    "        s = unzipPath+\"/_rels/.rels\", \n",
    "        xsl = pathToXlsxtoteiXSL, \n",
    "        o = output, \n",
    "        parameters=params\n",
    "    )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e041e152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:17,561 - data/WIBARAB_Recordings.xml\n"
     ]
    }
   ],
   "source": [
    "pathToTEItable=pathToExcelSheet.replace(\".xlsx\",\".xml\")\n",
    "\n",
    "if not \"xlsx2teitable\" in SKIP_PROCESSING:    \n",
    "    xlsx2teitable(xlsx=pathToExcelSheet, output=pathToTEItable)\n",
    "    debugstring=\"\"\"<!-- \n",
    "   THIS FILE IS INCLUDED IN THE GIT REPOSITORY ONLY FOR DEBUGGING PURPOSES. \n",
    "   \n",
    "   The source of this file is constantly being edited at \n",
    "   https://oeawacat.sharepoint.com/sites/ACDH-CH_p_ShawiTypeArabicDialects_Shawi/_layouts/15/Doc.aspx?sourcedoc={F01FF43B-2409-4E31-A5BF-653E0559B160}&file=SHAWI%20Recordings.xlsx&action=default&mobileredirect=true&cid=f7311564-c2b6-4b08-9a52-468547688408\n",
    "   So this copy is most probably already outdated.\n",
    "   \n",
    "  To update it, you can either run https://gitlab.com/acdh-oeaw/shawibarab/shawi-data/-/blob/main/080_scripts_generic/080_01_ELAN2TEI/ELAN2TEI.ipyn\n",
    "   *OR*  \n",
    "   1) download the Excel file manually from Sharepoint\n",
    "   2) and tranform it to TEI using oxgarage.tei-c.org/ \n",
    "   \n",
    "-->\n",
    "    \"\"\"\n",
    "    f = open(pathToTEItable,mode=\"r\",encoding=\"UTF8\")\n",
    "    src = f.read()\n",
    "    new = src.replace('<?xml version=\"1.0\" encoding=\"UTF-8\"?>','<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'+debugstring)\n",
    "    f.close()\n",
    "    f = open(pathToTEItable, mode=\"wt\",encoding=\"UTF8\")\n",
    "    f.write(new)\n",
    "    f.close()\n",
    "        \n",
    "    logging.info(pathToTEItable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca2fcd",
   "metadata": {},
   "source": [
    "## Step 3: transform TEI table to corpus header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0889b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:17,676 - ../../103_tei_w/wibarabCorpus.xml\n"
     ]
    }
   ],
   "source": [
    "pathToTeitableToCorpusXSL=pathToStylesheetsDir+\"/table2corpus.xsl\"\n",
    "params = {\n",
    "    \"pathToRecordings\" : pathlib.Path(os.path.abspath(pathToRecordingsDir)).as_uri(),\n",
    "    \"sp_pathToRecordingsXLSX\": sp_pathToRecordingsXLSX\n",
    "}\n",
    "try:\n",
    "    transform(pathToTEItable, pathToTeitableToCorpusXSL, pathToTeiCorpus, params)\n",
    "except saxonche.PySaxonApiError as e:\n",
    "    logging.error(\"an error occured: \" + str(e) + \"\\n\" + pathToTEItable + \": \" + pathToTeitableToCorpusXSL + \" -> \" + pathToTeiCorpus)\n",
    "logging.info(pathToTeiCorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd00c7",
   "metadata": {},
   "source": [
    "## Step 4: Run TEICorpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8914cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:19,065 - skipping download\n",
      "2023-10-23 10:53:19,472 - skipping download\n",
      "2023-10-23 10:53:19,474 - lib/*\n"
     ]
    }
   ],
   "source": [
    "def installFromUrl(url, force=False):\n",
    "    r = requests.get(url)\n",
    "    filename = os.path.basename(urlsplit(url).path)\n",
    "    downloadpath = libDir+\"/\"+filename\n",
    "    if os.path.exists(downloadpath) and not force:\n",
    "        logging.info(\"skipping download\")\n",
    "    else:\n",
    "        open(downloadpath, 'wb').write(r.content)\n",
    "        logging.info(\"file \"+downloadpath+\" downloaded\")\n",
    "    return downloadpath\n",
    "\n",
    "# TODO check for filetype and automatically extract zip file \n",
    "# so this can be re-used for the insta\n",
    " \n",
    "installFromUrl(\"https://github.com/christopheparisse/teicorpo/blob/e06a01ad5cb4c3aef631b3749ce59b5eb6f5ea11/teicorpo.jar?raw=true\")\n",
    "installFromUrl(\"https://repo1.maven.org/maven2/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar\")\n",
    "pathToTeiCorpo=libDir+\"/*\"\n",
    "logging.info(pathToTeiCorpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68193a14",
   "metadata": {},
   "source": [
    "Collect all ELAN documents from pathToELANDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc55161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:19,485 - /home/dschopper/data/WIBARAB/corpus/122_elan/03_NZ_M.73_Karantina_historyKarantina.eaf\n",
      "2023-10-23 10:53:19,486 - /home/dschopper/data/WIBARAB/corpus/122_elan/15_NZ_M.73_Karantina_ProphetstoryValues.eaf\n",
      "2023-10-23 10:53:19,487 - /home/dschopper/data/WIBARAB/corpus/122_elan/09_NZ_M.73_Karantina_creditSon.picturesWedding.eaf\n",
      "2023-10-23 10:53:19,488 - /home/dschopper/data/WIBARAB/corpus/122_elan/05_NZ_M.73_Karantina_shyuxa.eaf\n",
      "2023-10-23 10:53:19,488 - /home/dschopper/data/WIBARAB/corpus/122_elan/18_NZ_M.73_Karantina_tamerStory.eaf\n",
      "2023-10-23 10:53:19,489 - /home/dschopper/data/WIBARAB/corpus/122_elan/17_NZ_M.73_Karantina_shadirStory.eaf\n",
      "2023-10-23 10:53:19,489 - /home/dschopper/data/WIBARAB/corpus/122_elan/14_NZ_M.73_Karantina_Beirutbefore.eaf\n",
      "2023-10-23 10:53:19,490 - /home/dschopper/data/WIBARAB/corpus/122_elan/04_NZ_M.73_Karantina_Pictures.eaf\n",
      "2023-10-23 10:53:19,491 - /home/dschopper/data/WIBARAB/corpus/122_elan/01_NZ_M.73_Karantina_FirstEncounter.eaf\n",
      "2023-10-23 10:53:19,491 - /home/dschopper/data/WIBARAB/corpus/122_elan/SAU_2022_Speaker10_marriage.eaf\n",
      "2023-10-23 10:53:19,492 - /home/dschopper/data/WIBARAB/corpus/122_elan/16_NZ_M.73_Karantina_SaidaFriends.eaf\n",
      "2023-10-23 10:53:19,494 - /home/dschopper/data/WIBARAB/corpus/122_elan/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables.eaf\n",
      "2023-10-23 10:53:19,495 - /home/dschopper/data/WIBARAB/corpus/122_elan/08_NZ_M.73_Karantina_hisFamily.eaf\n",
      "2023-10-23 10:53:19,496 - /home/dschopper/data/WIBARAB/corpus/122_elan/SAU_2022_Speaker20_traditionaltools.eaf\n",
      "2023-10-23 10:53:19,497 - /home/dschopper/data/WIBARAB/corpus/122_elan/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan.eaf\n",
      "2023-10-23 10:53:19,497 - /home/dschopper/data/WIBARAB/corpus/122_elan/SAU_2022_Speaker20_shepherd.eaf\n",
      "2023-10-23 10:53:19,498 - /home/dschopper/data/WIBARAB/corpus/122_elan/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion.eaf\n",
      "2023-10-23 10:53:19,498 - /home/dschopper/data/WIBARAB/corpus/122_elan/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation.eaf\n",
      "2023-10-23 10:53:19,499 - /home/dschopper/data/WIBARAB/corpus/122_elan/02_NZ_M.73_Karantina_BedouinWeddings.eaf\n",
      "2023-10-23 10:53:19,500 - /home/dschopper/data/WIBARAB/corpus/122_elan/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity.eaf\n",
      "2023-10-23 10:53:19,501 - /home/dschopper/data/WIBARAB/corpus/122_elan/SAU_2022_Speaker14_childhood_womenswork.eaf\n",
      "2023-10-23 10:53:19,502 - /home/dschopper/data/WIBARAB/corpus/122_elan/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage.eaf\n"
     ]
    }
   ],
   "source": [
    "ELANDocs = []\n",
    "\n",
    "for i in os.scandir(pathToELANDir):\n",
    "    filename=os.path.basename(i)\n",
    "    if filename.endswith(\".eaf\"):\n",
    "        basename=Path(i).stem\n",
    "\n",
    "        # check whether there is already a manually annotated TEI version of this ELAN document\n",
    "        TEI_annotated_filename=pathToAnnotatedTEIDir+\"/\"+basename+\".xml\"\n",
    "        TEI_annotated_exists = os.path.exists(os.path.abspath(TEI_annotated_filename)) \n",
    "        TEI_annotated=os.path.abspath(TEI_annotated_filename) if TEI_annotated_exists else False\n",
    "        \n",
    "        ELANDocs.append({\n",
    "            \"filepath\" : os.path.abspath(i), # path to the ELAN document\n",
    "            \"filename\" : filename,\n",
    "            \"basename\" : basename,\n",
    "            \"TEI_annotated\" : TEI_annotated,\n",
    "            \"tmpDir\" : False,  # path to temporary output files (e.g. output of TEICorpo)\n",
    "            \"filepath_tmp_TEI\" : False, # path to the output of TEICorpo\n",
    "            \"TEI\" : False # path to the TEI representation of the ELAN document with metadata from the spreadsheet\n",
    "            \n",
    "        })\n",
    "        \n",
    "for d in ELANDocs:\n",
    "    logging.info(d[\"filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec70e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTEICorpo(docs = dict):\n",
    "    runtime = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    tmpDir = pathToTEIDir+\"/\"+runtime\n",
    "    os.makedirs(tmpDir, exist_ok=True)\n",
    "    for i in docs:\n",
    "        pathToInput = i[\"filepath\"]\n",
    "        filenameELAN = i[\"filename\"]\n",
    "        filenameTEI = i[\"basename\"]+\".xml\"\n",
    "        pathToOutput = tmpDir+\"/\"+\"ELAN_\"+filenameTEI\n",
    "        i[\"filepath_tmp_TEI\"] = os.path.abspath(pathToOutput)\n",
    "        i[\"tmpDir\"] = tmpDir\n",
    "        output = os.path.abspath(pathToTEIDir + \"/\" + i[\"basename\"] + \".xml\")\n",
    "        i[\"TEI\"] = os.path.abspath(output)\n",
    "        res = subprocess.run([\"java\", \"-cp\", pathToTeiCorpo, \"-Dfile.encoding=UTF-8\", \"fr.ortolang.teicorpo.TeiCorpo\", \"-from\",\"elan\", \"-to\",\"tei\", \"-o\",pathToOutput, pathToInput], capture_output=True, encoding=\"UTF-8\")\n",
    "        print(res.stdout)\n",
    "        print(res.stderr)\n",
    "        print(pathToOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38413b21",
   "metadata": {},
   "source": [
    "run TEI Corpo on all ELANDocs, writing the path to the TEI output back to the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2862351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_03_NZ_M.73_Karantina_historyKarantina.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_15_NZ_M.73_Karantina_ProphetstoryValues.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_09_NZ_M.73_Karantina_creditSon.picturesWedding.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_05_NZ_M.73_Karantina_shyuxa.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_18_NZ_M.73_Karantina_tamerStory.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_17_NZ_M.73_Karantina_shadirStory.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_14_NZ_M.73_Karantina_Beirutbefore.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_04_NZ_M.73_Karantina_Pictures.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_01_NZ_M.73_Karantina_FirstEncounter.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker10_marriage.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_16_NZ_M.73_Karantina_SaidaFriends.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_10_NZ_M.73_Karantina_GardenPlantsMarketVegetables.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_08_NZ_M.73_Karantina_hisFamily.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker20_traditionaltools.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker20_shepherd.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_13_NZ_M.73_Karantina_AnimalmarketFoodpreparation.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_02_NZ_M.73_Karantina_BedouinWeddings.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker14_childhood_womenswork.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "\n",
      "../../103_tei_w/2023-10-23_10-53/ELAN_07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage.xml\n"
     ]
    }
   ],
   "source": [
    "if not \"runTEICorpo\" in SKIP_PROCESSING:\n",
    "    runTEICorpo(docs=ELANDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51dc1f",
   "metadata": {},
   "source": [
    "## Step 5: Merge metadata and TEICorpo Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4a604e-d031-474c-9f8c-9d27bd4cb8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mergeMetadata(docInfo, p):\n",
    "    \"\"\"Tries to find the corpus metadata in WIBARABCorpus.xml for the TEICorpo output by comparing its filename to the tei:title elements in it (= IDs of the Recording table), \n",
    "       and then replaces the teiHeader in the TEICorpo output with it.\"\"\"\n",
    "    # TOOD The matching logic should be revised, it's too messy \n",
    "    # probably move to the jupyter-notebook instead of having it here.\n",
    "    \n",
    "    # <xsl:variable name=\"corpusDoc\" select=\"doc($pathToCorpusDoc)\" as=\"document-node()\"/>\n",
    "    # <xsl:variable name=\"IDcandidates\" select=\"$corpusDoc//*:title\"/>\n",
    "    # <xsl:variable name=\"pathSegs\" select=\"tokenize(base-uri($input),'/')\"/>\n",
    "    # <xsl:variable name=\"recordingID\" select=\"$IDcandidates[some $x in $pathSegs satisfies contains(lower-case($x), lower-case(.))]\"/>\n",
    "    \n",
    "    # pathToTmpTEI: \n",
    "    pathToTmpTEI=docInfo[\"filepath_tmp_TEI\"]\n",
    "    pathToMergedTEI=docInfo[\"tmpDir\"]+\"/\"+docInfo[\"basename\"]+\"_00_metaMerged.xml\"\n",
    "    \n",
    "    logging.info(\"trying to inject metadata from \"+p[\"pathToCorpusDoc\"]+\" into \"+pathToTmpTEI)\n",
    "    \n",
    "    try:\n",
    "        transform(s=pathToTmpTEI, xsl=pathToStylesheetsDir+\"/mergeHeaderAndTranscription.xsl\", o=pathToMergedTEI, parameters=p)\n",
    "    except saxonche.PySaxonApiError as e:\n",
    "        logging.error(\"an error occured: \" + str(e) + \"\\n\" + s + \": \" + pathToPostprocessXSL + \" -> \" + s)\n",
    "    \n",
    "    # check wether the output file is well-formed\n",
    "    #try:\n",
    "    #    parsed = etree.parse(pathToMergedTEI)\n",
    "   #     if parsed:\n",
    "    docInfo[\"filepath_tmp_00_mergedMetadata\"]=pathToMergedTEI\n",
    "    return pathToMergedTEI\n",
    "    \n",
    "    #except etree.XMLSyntaxError as e:\n",
    "     #   logging.error(\"merge metadata resulted in an non-wellformed (empty?) XML document\")\n",
    "      #  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf59e5-5e62-4bd0-ae65-a303184540ee",
   "metadata": {},
   "source": [
    "## Step 6: Post-process merged TEI document prior to tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8633ee75-f7c7-40be-8564-c475eaa0e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcessMergedTEI(docObject, pathToInput):\n",
    "    \"\"\"applies a post-process XSLT to the merged document prior to \"\"\"\n",
    "    s = pathToInput #docInfo[\"filepath_tmp_TEImergedMetadata\"]\n",
    "    o = s\n",
    "    logging.info(\"running post-metadata-merge processing on \"+s)\n",
    "    if not os.path.exists(os.path.abspath(s)):\n",
    "        logging.error(\"file \"+s+\" does not exist.\")\n",
    "    else:\n",
    "        pathToPostprocessXSL=pathToStylesheetsDir+\"/postprocessTEICorpoOutput.xsl\"\n",
    "        try:\n",
    "            transform(s, pathToPostprocessXSL, o, {})\n",
    "        except saxonche.PySaxonApiError as e:\n",
    "            logging.error(\"an error occured: \" + str(e) + \"\\n\" + s + \": \" + pathToPostprocessXSL + \" -> \" + o)\n",
    "    \n",
    "        # check wether the output file is well-formed\n",
    "        #try:\n",
    "        #    parsed = etree.parse(o)\n",
    "        #    if parsed:\n",
    "        docObject[\"filepath_tmp_TEImergedMetadata\"]=o\n",
    "        return o\n",
    "        #except etree.XMLSyntaxError as e:\n",
    "        #    logging.error(\"post-processing merged TEI document resulted in an non-wellformed (empty?) XML document\")\n",
    "        #    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a7c29-d7bb-47c7-ba8b-d1073168d67d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 7: Tokenization of unannotated texts\n",
    "\n",
    "Run a local copy of [xsl-tokenizer](https://github.com/acdh-oeaw/xsl-tokenizer)\n",
    "\n",
    "The merged TEI document is tokenized for further manual annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302385d4-f8b0-4f9c-bdfa-75a645e884f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7.0: (Re-)generate tokenizer stylesheets (optional)\n",
    "\n",
    "Regenerate the XSLs used in the following steps.\n",
    "This can not be done with saxonpy (xincludes are not resolved)\n",
    "use\n",
    "```bash\n",
    "java -jar Saxon-HE-9.9.1-8.jar -s:profile.xml -xi:on -xsl:xsl/make_xsl.xsl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b9698-1946-4114-ba8b-5d2caca7b7f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "For all the ELAN files converted to TEI:\n",
    "\n",
    "### Step 7.1: Remove new lines\n",
    "\n",
    "Remove new lines and store to intermediate document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feb48707-d990-4737-8115-277497add47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNL(docObject, pathToInput):\n",
    "    s = pathToInput # docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_00_metaMerged.xml\"\n",
    "    o = docObject[\"tmpDir\"]+'/'+docObject[\"basename\"]+\"_01_nlRmd.xml\"\n",
    "    logging.info(\"removing new lines from \"+s)\n",
    "    transform(s = s, xsl = \"./tokenizer/xsl/rmNl.xsl\", o = o)\n",
    "    # check wether the output file is well-formed\n",
    "    #try:\n",
    "    #    parsed = etree.parse(o)\n",
    "    #    if parsed:\n",
    "    docObject[\"filepath_tmp_t0_rmnl\"]=o\n",
    "    return o\n",
    "    #except etree.XMLSyntaxError as e:\n",
    "    #    logging.error(\"tokenizing step 0 / removing newlines resulted in an non-wellformed (empty?) XML document\")\n",
    "    #    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95efdd-eaaa-4132-a42b-e70f6a0225b5",
   "metadata": {},
   "source": [
    "### Step 7.2: create w tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a825ea8-f03d-4f56-b4ef-158817e5cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(docInfo, pathToInput):\n",
    "    s = pathToInput # docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_01_nlRmd.xml\"\n",
    "    logging.info(\"tokenizing \"+s)\n",
    "    o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_02_toks.xml\"\n",
    "    transform(s = s, xsl = \"./tokenizer/wrapper_toks.xsl\", o = o)\n",
    "    # check wether the output file is well-formed\n",
    "    #try:\n",
    "    #    parsed = etree.parse(o)\n",
    "    #    if parsed:\n",
    "    docInfo[\"filepath_tmp_t1_w\"]=o\n",
    "    return o\n",
    "    #except etree.XMLSyntaxError as e:\n",
    "    #    logging.error(\"tokenizing step 1 / tokenization resulted in an non-wellformed (empty?) XML document\")\n",
    "    #    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33998805-c4f2-4039-999b-419acb3e69f9",
   "metadata": {},
   "source": [
    "### Step 7.3: Add part attributes to w tags\n",
    "\n",
    "Add Part-Attributes and explicit token links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3946396-3a73-4180-873f-2361a669cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addP(docInfo, pathToInput):\n",
    "    s = pathToInput #docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_02_toks.xml\"\n",
    "    logging.info(\"adding @part on <w>\")\n",
    "    o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_03_tokenized.xml\"\n",
    "    transform(s = s, xsl = \"./tokenizer/wrapper_addP.xsl\", o = o)\n",
    "    # check wether the output file is well-formed\n",
    "    #try:\n",
    "    #    parsed = etree.parse(o)\n",
    "    #    if parsed:\n",
    "    docInfo[\"filepath_tmp_t2_part\"]=o\n",
    "    return o\n",
    "    #except etree.XMLSyntaxError as e:\n",
    "    #    logging.error(\"tokenizing step 2 / adding w/@part resulted in an non-wellformed (empty?) XML document\")\n",
    "    #    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729253b-f6e2-42b8-b4ef-e67319aed15b",
   "metadata": {},
   "source": [
    "### Step 7.4: apply project-specific post-processing\n",
    "\n",
    "Do some post tokenization processing specific to the Shawi project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6292bd18-6718-4d64-97c7-c4c093283f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcess(docInfo, pathToInput):\n",
    "    s = pathToInput #docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_03_tokenized.xml\"\n",
    "    logging.info(\"applying post-tokenization processing to \"+s)\n",
    "    o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\"\n",
    "    transform(s = s, xsl = \"./tokenizer/postTokenization/1.xsl\", o = o)\n",
    "    # check wether the output file is well-formed\n",
    "    #try:\n",
    "    #    parsed = etree.parse(o)\n",
    "    #    if parsed:\n",
    "    docInfo[\"filepath_tmp_t3_post\"]=o\n",
    "    return o\n",
    "    #except etree.XMLSyntaxError as e:\n",
    "    #    logging.error(\"tokenizing step 4 / postprocessing resulted in an non-wellformed (empty?) XML document\")\n",
    "    #    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e721c-bb9e-4a7b-b6fd-be53e06b14b3",
   "metadata": {},
   "source": [
    "## Step 6.5: move token namespace from xtoks to TEI \n",
    "\n",
    "**--> This step creates the files which data curators will copy to `010_manannot` and annotate using the TEI enricher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44f2ec8a-fe7e-4142-9382-b5cd3bfd30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTEIForAnnotation(docInfo, pathToInput):\n",
    "    s = pathToInput # output of postProcess = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\"\n",
    "    o = docInfo[\"TEI\"]\n",
    "    logging.info(\"creating TEI document for annotation from \"+s)\n",
    "    transform(s = s, xsl = \"./tokenizer/custom_xtoks2tei.xsl\", o = o, parameters = {\"preserve-ws\": \"false\"})\n",
    "    \n",
    "    #try:\n",
    "    #    parsed = etree.parse(o)\n",
    "    #    if parsed:\n",
    "    return o\n",
    "    #except etree.XMLSyntaxError as e:\n",
    "    #    logging.error(\"tokenizing step 5 / custom_xtoks2tei resulted in an non-wellformed (empty?) XML document\")\n",
    "    #    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44acba-435d-449c-afc1-1288233036e1",
   "metadata": {},
   "source": [
    "## Step 7: Create NoSke input\n",
    "\n",
    "We create verticals from the unannotated texts and attach the token annotations from `010_manannot` to them.\n",
    "\n",
    "### Step 7.1 Create XML vertical from tokenized XML documents\n",
    "\n",
    "We take the tokenized XML document (prior to have moved to TEI) and create an XML vertical from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2e07285-908a-4f6e-89ff-43b4f59e103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXMLVert(docInfo, pathToInput):\n",
    "    s = pathToInput # output of postProcess = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\"\n",
    "    logging.info(\"creating XML vertical from \"+s)\n",
    "    o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_05_vert.xml\"\n",
    "    transform(s = s, xsl = \"./tokenizer/custom_xtoks2vert.xsl\", o = o)\n",
    "    \n",
    "    #try:\n",
    "    #    parsed = etree.parse(o)\n",
    "    #    if parsed:\n",
    "    return o\n",
    "    #except etree.XMLSyntaxError as e:\n",
    "    #    logging.error(\"tokenizing step 5 / custom_xtoks2tei resulted in an non-wellformed (empty?) XML document\")\n",
    "    #return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29a7e0-e42c-4e87-a443-17501b1191cc",
   "metadata": {},
   "source": [
    "### Step 7.2: attach manual annotations to the XML vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01c0cfa1-cba3-4480-b040-94749902527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attachAnnotationsToXMLVert(docInfo, pathToXMLVertical):\n",
    "    \"\"\"Try to add existing annotations to the newly converted document, if they exist.\"\"\"\n",
    "    if docInfo[\"TEI_annotated\"] and os.path.exists(os.path.abspath(docInfo[\"TEI_annotated\"])):\n",
    "        transform(\n",
    "            s = pathToXMLVertical, #docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_05_vert.xml\",\n",
    "            xsl = pathToStylesheetsDir+\"/copyAnaToVert.xsl\", \n",
    "            o = docInfo[\"tmpDir\"] + \"/\" + docInfo[\"basename\"] + \"_05_vert_annot.xml\",\n",
    "            parameters = {\n",
    "                \"path_to_annotated_doc\": pathlib.Path(os.path.abspath(docInfo[\"TEI_annotated\"])).as_uri()\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\"No previous annotations found for \"+docInfo[\"basename\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107ed8f-dfa4-41b8-9f24-c63a9c71589c",
   "metadata": {},
   "source": [
    "### Step 7.3 convert XML vertical to text vertical\n",
    "\n",
    "Create a vertical vor NoSkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed763150-c07c-45d0-b077-05f8839e3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNoSkEVert(docInfo, pathToInput):\n",
    "    s = pathToInput # docInfo[\"tmpDir\"] + \"/\" + docInfo[\"basename\"] + \"_05_vert_annot.xml\"\n",
    "    o = noSkEVertDir + \"/\" + docInfo[\"basename\"] + \".txt\"\n",
    "    transform( s = s,xsl = \"./tokenizer/wrapper_vert2txt.xsl\", o = o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b488db-49d5-4f4b-a81c-f4e2dbf712d0",
   "metadata": {},
   "source": [
    "## Run Steps 6- 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f24c432-2ac1-48d8-a50f-604b34b808d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 10:53:29,603 - \n",
      "\n",
      "*** processing 03_NZ_M.73_Karantina_historyKarantina: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_03_NZ_M.73_Karantina_historyKarantina.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/03_NZ_M.73_Karantina_historyKarantina.xml\n",
      "2023-10-23 10:53:29,604 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_03_NZ_M.73_Karantina_historyKarantina.xml\n",
      "$recordingID could not be determined from input filename ELAN_03_NZ_M.73_Karantina_historyKarantina.xml\n",
      "2023-10-23 10:53:29,646 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/03_NZ_M.73_Karantina_historyKarantina_00_metaMerged.xml\n",
      "teiHeader for recording  not found in file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml\n",
      "2023-10-23 10:53:29,653 - removing new lines from ../../103_tei_w/2023-10-23_10-53/03_NZ_M.73_Karantina_historyKarantina_00_metaMerged.xml\n",
      "2023-10-23 10:53:29,665 - tokenizing ../../103_tei_w/2023-10-23_10-53/03_NZ_M.73_Karantina_historyKarantina_01_nlRmd.xml\n",
      "2023-10-23 10:53:29,680 - adding @part on <w>\n",
      "2023-10-23 10:53:29,729 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/03_NZ_M.73_Karantina_historyKarantina_03_tokenized.xml\n",
      "2023-10-23 10:53:29,758 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/03_NZ_M.73_Karantina_historyKarantina_04_posttok.xml\n",
      "2023-10-23 10:53:29,777 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/03_NZ_M.73_Karantina_historyKarantina_04_posttok.xml\n",
      "2023-10-23 10:53:29,826 - No previous annotations found for 03_NZ_M.73_Karantina_historyKarantina\n",
      "2023-10-23 10:53:29,844 - 03_NZ_M.73_Karantina_historyKarantina: done.\n",
      "2023-10-23 10:53:29,845 - \n",
      "\n",
      "*** processing 15_NZ_M.73_Karantina_ProphetstoryValues: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_15_NZ_M.73_Karantina_ProphetstoryValues.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/15_NZ_M.73_Karantina_ProphetstoryValues.xml\n",
      "2023-10-23 10:53:29,846 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_15_NZ_M.73_Karantina_ProphetstoryValues.xml\n",
      "2023-10-23 10:53:29,896 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/15_NZ_M.73_Karantina_ProphetstoryValues_00_metaMerged.xml\n",
      "2023-10-23 10:53:29,907 - removing new lines from ../../103_tei_w/2023-10-23_10-53/15_NZ_M.73_Karantina_ProphetstoryValues_00_metaMerged.xml\n",
      "2023-10-23 10:53:29,919 - tokenizing ../../103_tei_w/2023-10-23_10-53/15_NZ_M.73_Karantina_ProphetstoryValues_01_nlRmd.xml\n",
      "2023-10-23 10:53:29,937 - adding @part on <w>\n",
      "2023-10-23 10:53:29,981 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/15_NZ_M.73_Karantina_ProphetstoryValues_03_tokenized.xml\n",
      "2023-10-23 10:53:30,003 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/15_NZ_M.73_Karantina_ProphetstoryValues_04_posttok.xml\n",
      "2023-10-23 10:53:30,021 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/15_NZ_M.73_Karantina_ProphetstoryValues_04_posttok.xml\n",
      "2023-10-23 10:53:30,043 - No previous annotations found for 15_NZ_M.73_Karantina_ProphetstoryValues\n",
      "2023-10-23 10:53:30,058 - 15_NZ_M.73_Karantina_ProphetstoryValues: done.\n",
      "2023-10-23 10:53:30,060 - \n",
      "\n",
      "*** processing 09_NZ_M.73_Karantina_creditSon.picturesWedding: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_09_NZ_M.73_Karantina_creditSon.picturesWedding.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/09_NZ_M.73_Karantina_creditSon.picturesWedding.xml\n",
      "2023-10-23 10:53:30,061 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_09_NZ_M.73_Karantina_creditSon.picturesWedding.xml\n",
      "2023-10-23 10:53:30,097 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/09_NZ_M.73_Karantina_creditSon.picturesWedding_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,103 - removing new lines from ../../103_tei_w/2023-10-23_10-53/09_NZ_M.73_Karantina_creditSon.picturesWedding_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,112 - tokenizing ../../103_tei_w/2023-10-23_10-53/09_NZ_M.73_Karantina_creditSon.picturesWedding_01_nlRmd.xml\n",
      "2023-10-23 10:53:30,131 - adding @part on <w>\n",
      "2023-10-23 10:53:30,193 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/09_NZ_M.73_Karantina_creditSon.picturesWedding_03_tokenized.xml\n",
      "2023-10-23 10:53:30,212 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/09_NZ_M.73_Karantina_creditSon.picturesWedding_04_posttok.xml\n",
      "2023-10-23 10:53:30,235 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/09_NZ_M.73_Karantina_creditSon.picturesWedding_04_posttok.xml\n",
      "2023-10-23 10:53:30,262 - No previous annotations found for 09_NZ_M.73_Karantina_creditSon.picturesWedding\n",
      "2023-10-23 10:53:30,280 - 09_NZ_M.73_Karantina_creditSon.picturesWedding: done.\n",
      "2023-10-23 10:53:30,280 - \n",
      "\n",
      "*** processing 05_NZ_M.73_Karantina_shyuxa: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_05_NZ_M.73_Karantina_shyuxa.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/05_NZ_M.73_Karantina_shyuxa.xml\n",
      "2023-10-23 10:53:30,281 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_05_NZ_M.73_Karantina_shyuxa.xml\n",
      "2023-10-23 10:53:30,317 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/05_NZ_M.73_Karantina_shyuxa_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,323 - removing new lines from ../../103_tei_w/2023-10-23_10-53/05_NZ_M.73_Karantina_shyuxa_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,374 - tokenizing ../../103_tei_w/2023-10-23_10-53/05_NZ_M.73_Karantina_shyuxa_01_nlRmd.xml\n",
      "2023-10-23 10:53:30,383 - adding @part on <w>\n",
      "2023-10-23 10:53:30,418 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/05_NZ_M.73_Karantina_shyuxa_03_tokenized.xml\n",
      "2023-10-23 10:53:30,434 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/05_NZ_M.73_Karantina_shyuxa_04_posttok.xml\n",
      "2023-10-23 10:53:30,448 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/05_NZ_M.73_Karantina_shyuxa_04_posttok.xml\n",
      "2023-10-23 10:53:30,467 - No previous annotations found for 05_NZ_M.73_Karantina_shyuxa\n",
      "2023-10-23 10:53:30,483 - 05_NZ_M.73_Karantina_shyuxa: done.\n",
      "2023-10-23 10:53:30,484 - \n",
      "\n",
      "*** processing 18_NZ_M.73_Karantina_tamerStory: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_18_NZ_M.73_Karantina_tamerStory.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/18_NZ_M.73_Karantina_tamerStory.xml\n",
      "2023-10-23 10:53:30,485 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_18_NZ_M.73_Karantina_tamerStory.xml\n",
      "2023-10-23 10:53:30,524 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/18_NZ_M.73_Karantina_tamerStory_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,531 - removing new lines from ../../103_tei_w/2023-10-23_10-53/18_NZ_M.73_Karantina_tamerStory_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,542 - tokenizing ../../103_tei_w/2023-10-23_10-53/18_NZ_M.73_Karantina_tamerStory_01_nlRmd.xml\n",
      "2023-10-23 10:53:30,553 - adding @part on <w>\n",
      "2023-10-23 10:53:30,608 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/18_NZ_M.73_Karantina_tamerStory_03_tokenized.xml\n",
      "2023-10-23 10:53:30,623 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/18_NZ_M.73_Karantina_tamerStory_04_posttok.xml\n",
      "2023-10-23 10:53:30,641 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/18_NZ_M.73_Karantina_tamerStory_04_posttok.xml\n",
      "2023-10-23 10:53:30,662 - No previous annotations found for 18_NZ_M.73_Karantina_tamerStory\n",
      "2023-10-23 10:53:30,675 - 18_NZ_M.73_Karantina_tamerStory: done.\n",
      "2023-10-23 10:53:30,676 - \n",
      "\n",
      "*** processing 17_NZ_M.73_Karantina_shadirStory: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_17_NZ_M.73_Karantina_shadirStory.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/17_NZ_M.73_Karantina_shadirStory.xml\n",
      "2023-10-23 10:53:30,677 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_17_NZ_M.73_Karantina_shadirStory.xml\n",
      "2023-10-23 10:53:30,724 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/17_NZ_M.73_Karantina_shadirStory_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,751 - removing new lines from ../../103_tei_w/2023-10-23_10-53/17_NZ_M.73_Karantina_shadirStory_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,763 - tokenizing ../../103_tei_w/2023-10-23_10-53/17_NZ_M.73_Karantina_shadirStory_01_nlRmd.xml\n",
      "2023-10-23 10:53:30,779 - adding @part on <w>\n",
      "2023-10-23 10:53:30,843 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/17_NZ_M.73_Karantina_shadirStory_03_tokenized.xml\n",
      "2023-10-23 10:53:30,868 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/17_NZ_M.73_Karantina_shadirStory_04_posttok.xml\n",
      "2023-10-23 10:53:30,887 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/17_NZ_M.73_Karantina_shadirStory_04_posttok.xml\n",
      "2023-10-23 10:53:30,915 - No previous annotations found for 17_NZ_M.73_Karantina_shadirStory\n",
      "2023-10-23 10:53:30,934 - 17_NZ_M.73_Karantina_shadirStory: done.\n",
      "2023-10-23 10:53:30,934 - \n",
      "\n",
      "*** processing 14_NZ_M.73_Karantina_Beirutbefore: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_14_NZ_M.73_Karantina_Beirutbefore.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/14_NZ_M.73_Karantina_Beirutbefore.xml\n",
      "2023-10-23 10:53:30,935 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_14_NZ_M.73_Karantina_Beirutbefore.xml\n",
      "2023-10-23 10:53:30,984 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/14_NZ_M.73_Karantina_Beirutbefore_00_metaMerged.xml\n",
      "2023-10-23 10:53:30,992 - removing new lines from ../../103_tei_w/2023-10-23_10-53/14_NZ_M.73_Karantina_Beirutbefore_00_metaMerged.xml\n",
      "2023-10-23 10:53:31,004 - tokenizing ../../103_tei_w/2023-10-23_10-53/14_NZ_M.73_Karantina_Beirutbefore_01_nlRmd.xml\n",
      "2023-10-23 10:53:31,027 - adding @part on <w>\n",
      "2023-10-23 10:53:31,144 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/14_NZ_M.73_Karantina_Beirutbefore_03_tokenized.xml\n",
      "2023-10-23 10:53:31,167 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/14_NZ_M.73_Karantina_Beirutbefore_04_posttok.xml\n",
      "2023-10-23 10:53:31,186 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/14_NZ_M.73_Karantina_Beirutbefore_04_posttok.xml\n",
      "2023-10-23 10:53:31,217 - No previous annotations found for 14_NZ_M.73_Karantina_Beirutbefore\n",
      "2023-10-23 10:53:31,244 - 14_NZ_M.73_Karantina_Beirutbefore: done.\n",
      "2023-10-23 10:53:31,246 - \n",
      "\n",
      "*** processing 04_NZ_M.73_Karantina_Pictures: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_04_NZ_M.73_Karantina_Pictures.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/04_NZ_M.73_Karantina_Pictures.xml\n",
      "2023-10-23 10:53:31,246 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_04_NZ_M.73_Karantina_Pictures.xml\n",
      "2023-10-23 10:53:31,296 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/04_NZ_M.73_Karantina_Pictures_00_metaMerged.xml\n",
      "2023-10-23 10:53:31,315 - removing new lines from ../../103_tei_w/2023-10-23_10-53/04_NZ_M.73_Karantina_Pictures_00_metaMerged.xml\n",
      "2023-10-23 10:53:31,334 - tokenizing ../../103_tei_w/2023-10-23_10-53/04_NZ_M.73_Karantina_Pictures_01_nlRmd.xml\n",
      "2023-10-23 10:53:31,369 - adding @part on <w>\n",
      "2023-10-23 10:53:31,556 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/04_NZ_M.73_Karantina_Pictures_03_tokenized.xml\n",
      "2023-10-23 10:53:31,606 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/04_NZ_M.73_Karantina_Pictures_04_posttok.xml\n",
      "2023-10-23 10:53:31,652 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/04_NZ_M.73_Karantina_Pictures_04_posttok.xml\n",
      "2023-10-23 10:53:31,732 - No previous annotations found for 04_NZ_M.73_Karantina_Pictures\n",
      "2023-10-23 10:53:31,772 - 04_NZ_M.73_Karantina_Pictures: done.\n",
      "2023-10-23 10:53:31,773 - \n",
      "\n",
      "*** processing 01_NZ_M.73_Karantina_FirstEncounter: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_01_NZ_M.73_Karantina_FirstEncounter.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/01_NZ_M.73_Karantina_FirstEncounter.xml\n",
      "2023-10-23 10:53:31,774 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_01_NZ_M.73_Karantina_FirstEncounter.xml\n",
      "2023-10-23 10:53:31,822 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/01_NZ_M.73_Karantina_FirstEncounter_00_metaMerged.xml\n",
      "2023-10-23 10:53:31,846 - removing new lines from ../../103_tei_w/2023-10-23_10-53/01_NZ_M.73_Karantina_FirstEncounter_00_metaMerged.xml\n",
      "2023-10-23 10:53:31,871 - tokenizing ../../103_tei_w/2023-10-23_10-53/01_NZ_M.73_Karantina_FirstEncounter_01_nlRmd.xml\n",
      "2023-10-23 10:53:31,908 - adding @part on <w>\n",
      "2023-10-23 10:53:32,364 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/01_NZ_M.73_Karantina_FirstEncounter_03_tokenized.xml\n",
      "2023-10-23 10:53:32,511 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/01_NZ_M.73_Karantina_FirstEncounter_04_posttok.xml\n",
      "2023-10-23 10:53:32,578 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/01_NZ_M.73_Karantina_FirstEncounter_04_posttok.xml\n",
      "2023-10-23 10:53:32,681 - No previous annotations found for 01_NZ_M.73_Karantina_FirstEncounter\n",
      "2023-10-23 10:53:32,759 - 01_NZ_M.73_Karantina_FirstEncounter: done.\n",
      "2023-10-23 10:53:32,760 - \n",
      "\n",
      "*** processing SAU_2022_Speaker10_marriage: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker10_marriage.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/SAU_2022_Speaker10_marriage.xml\n",
      "2023-10-23 10:53:32,761 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker10_marriage.xml\n",
      "$recordingID could not be determined from input filename ELAN_SAU_2022_Speaker10_marriage.xml\n",
      "teiHeader for recording  not found in file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml\n",
      "2023-10-23 10:53:32,817 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker10_marriage_00_metaMerged.xml\n",
      "2023-10-23 10:53:32,848 - removing new lines from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker10_marriage_00_metaMerged.xml\n",
      "2023-10-23 10:53:32,875 - tokenizing ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker10_marriage_01_nlRmd.xml\n",
      "2023-10-23 10:53:32,940 - adding @part on <w>\n",
      "2023-10-23 10:53:34,307 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker10_marriage_03_tokenized.xml\n",
      "2023-10-23 10:53:34,477 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker10_marriage_04_posttok.xml\n",
      "2023-10-23 10:53:34,594 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker10_marriage_04_posttok.xml\n",
      "2023-10-23 10:53:34,791 - No previous annotations found for SAU_2022_Speaker10_marriage\n",
      "2023-10-23 10:53:34,936 - SAU_2022_Speaker10_marriage: done.\n",
      "2023-10-23 10:53:34,937 - \n",
      "\n",
      "*** processing 16_NZ_M.73_Karantina_SaidaFriends: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_16_NZ_M.73_Karantina_SaidaFriends.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/16_NZ_M.73_Karantina_SaidaFriends.xml\n",
      "2023-10-23 10:53:34,937 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_16_NZ_M.73_Karantina_SaidaFriends.xml\n",
      "2023-10-23 10:53:34,979 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/16_NZ_M.73_Karantina_SaidaFriends_00_metaMerged.xml\n",
      "2023-10-23 10:53:34,986 - removing new lines from ../../103_tei_w/2023-10-23_10-53/16_NZ_M.73_Karantina_SaidaFriends_00_metaMerged.xml\n",
      "2023-10-23 10:53:34,997 - tokenizing ../../103_tei_w/2023-10-23_10-53/16_NZ_M.73_Karantina_SaidaFriends_01_nlRmd.xml\n",
      "2023-10-23 10:53:35,012 - adding @part on <w>\n",
      "2023-10-23 10:53:35,056 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/16_NZ_M.73_Karantina_SaidaFriends_03_tokenized.xml\n",
      "2023-10-23 10:53:35,085 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/16_NZ_M.73_Karantina_SaidaFriends_04_posttok.xml\n",
      "2023-10-23 10:53:35,116 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/16_NZ_M.73_Karantina_SaidaFriends_04_posttok.xml\n",
      "2023-10-23 10:53:35,154 - No previous annotations found for 16_NZ_M.73_Karantina_SaidaFriends\n",
      "2023-10-23 10:53:35,171 - 16_NZ_M.73_Karantina_SaidaFriends: done.\n",
      "2023-10-23 10:53:35,172 - \n",
      "\n",
      "*** processing 10_NZ_M.73_Karantina_GardenPlantsMarketVegetables: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_10_NZ_M.73_Karantina_GardenPlantsMarketVegetables.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables.xml\n",
      "2023-10-23 10:53:35,172 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_10_NZ_M.73_Karantina_GardenPlantsMarketVegetables.xml\n",
      "2023-10-23 10:53:35,208 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables_00_metaMerged.xml\n",
      "2023-10-23 10:53:35,222 - removing new lines from ../../103_tei_w/2023-10-23_10-53/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables_00_metaMerged.xml\n",
      "2023-10-23 10:53:35,235 - tokenizing ../../103_tei_w/2023-10-23_10-53/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables_01_nlRmd.xml\n",
      "2023-10-23 10:53:35,254 - adding @part on <w>\n",
      "2023-10-23 10:53:35,319 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables_03_tokenized.xml\n",
      "2023-10-23 10:53:35,346 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables_04_posttok.xml\n",
      "2023-10-23 10:53:35,365 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/10_NZ_M.73_Karantina_GardenPlantsMarketVegetables_04_posttok.xml\n",
      "2023-10-23 10:53:35,399 - No previous annotations found for 10_NZ_M.73_Karantina_GardenPlantsMarketVegetables\n",
      "2023-10-23 10:53:35,421 - 10_NZ_M.73_Karantina_GardenPlantsMarketVegetables: done.\n",
      "2023-10-23 10:53:35,422 - \n",
      "\n",
      "*** processing 08_NZ_M.73_Karantina_hisFamily: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_08_NZ_M.73_Karantina_hisFamily.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/08_NZ_M.73_Karantina_hisFamily.xml\n",
      "2023-10-23 10:53:35,422 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_08_NZ_M.73_Karantina_hisFamily.xml\n",
      "2023-10-23 10:53:35,476 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/08_NZ_M.73_Karantina_hisFamily_00_metaMerged.xml\n",
      "2023-10-23 10:53:35,499 - removing new lines from ../../103_tei_w/2023-10-23_10-53/08_NZ_M.73_Karantina_hisFamily_00_metaMerged.xml\n",
      "2023-10-23 10:53:35,624 - tokenizing ../../103_tei_w/2023-10-23_10-53/08_NZ_M.73_Karantina_hisFamily_01_nlRmd.xml\n",
      "2023-10-23 10:53:35,640 - adding @part on <w>\n",
      "2023-10-23 10:53:35,703 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/08_NZ_M.73_Karantina_hisFamily_03_tokenized.xml\n",
      "2023-10-23 10:53:35,738 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/08_NZ_M.73_Karantina_hisFamily_04_posttok.xml\n",
      "2023-10-23 10:53:35,761 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/08_NZ_M.73_Karantina_hisFamily_04_posttok.xml\n",
      "2023-10-23 10:53:35,799 - No previous annotations found for 08_NZ_M.73_Karantina_hisFamily\n",
      "2023-10-23 10:53:35,822 - 08_NZ_M.73_Karantina_hisFamily: done.\n",
      "2023-10-23 10:53:35,823 - \n",
      "\n",
      "*** processing SAU_2022_Speaker20_traditionaltools: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker20_traditionaltools.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/SAU_2022_Speaker20_traditionaltools.xml\n",
      "2023-10-23 10:53:35,824 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker20_traditionaltools.xml\n",
      "2023-10-23 10:53:35,874 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_traditionaltools_00_metaMerged.xml\n",
      "2023-10-23 10:53:35,894 - removing new lines from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_traditionaltools_00_metaMerged.xml\n",
      "2023-10-23 10:53:35,916 - tokenizing ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_traditionaltools_01_nlRmd.xml\n",
      "2023-10-23 10:53:35,965 - adding @part on <w>\n",
      "2023-10-23 10:53:36,412 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_traditionaltools_03_tokenized.xml\n",
      "2023-10-23 10:53:36,506 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_traditionaltools_04_posttok.xml\n",
      "2023-10-23 10:53:36,575 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_traditionaltools_04_posttok.xml\n",
      "2023-10-23 10:53:36,680 - No previous annotations found for SAU_2022_Speaker20_traditionaltools\n",
      "2023-10-23 10:53:36,756 - SAU_2022_Speaker20_traditionaltools: done.\n",
      "2023-10-23 10:53:36,757 - \n",
      "\n",
      "*** processing 06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan.xml\n",
      "2023-10-23 10:53:36,758 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan.xml\n",
      "2023-10-23 10:53:36,794 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan_00_metaMerged.xml\n",
      "2023-10-23 10:53:36,804 - removing new lines from ../../103_tei_w/2023-10-23_10-53/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan_00_metaMerged.xml\n",
      "2023-10-23 10:53:36,818 - tokenizing ../../103_tei_w/2023-10-23_10-53/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan_01_nlRmd.xml\n",
      "2023-10-23 10:53:36,834 - adding @part on <w>\n",
      "2023-10-23 10:53:36,885 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan_03_tokenized.xml\n",
      "2023-10-23 10:53:36,906 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan_04_posttok.xml\n",
      "2023-10-23 10:53:36,930 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan_04_posttok.xml\n",
      "2023-10-23 10:53:36,961 - No previous annotations found for 06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan\n",
      "2023-10-23 10:53:36,980 - 06_NZ_M.73_Karantina_eliciationIMP.StoryBedouinMan: done.\n",
      "2023-10-23 10:53:36,980 - \n",
      "\n",
      "*** processing SAU_2022_Speaker20_shepherd: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker20_shepherd.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/SAU_2022_Speaker20_shepherd.xml\n",
      "2023-10-23 10:53:36,981 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker20_shepherd.xml\n",
      "2023-10-23 10:53:37,017 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_shepherd_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,031 - removing new lines from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_shepherd_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,044 - tokenizing ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_shepherd_01_nlRmd.xml\n",
      "2023-10-23 10:53:37,066 - adding @part on <w>\n",
      "2023-10-23 10:53:37,191 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_shepherd_03_tokenized.xml\n",
      "2023-10-23 10:53:37,262 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_shepherd_04_posttok.xml\n",
      "2023-10-23 10:53:37,299 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker20_shepherd_04_posttok.xml\n",
      "2023-10-23 10:53:37,352 - No previous annotations found for SAU_2022_Speaker20_shepherd\n",
      "2023-10-23 10:53:37,382 - SAU_2022_Speaker20_shepherd: done.\n",
      "2023-10-23 10:53:37,382 - \n",
      "\n",
      "*** processing 12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion.xml\n",
      "2023-10-23 10:53:37,383 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion.xml\n",
      "2023-10-23 10:53:37,418 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,428 - removing new lines from ../../103_tei_w/2023-10-23_10-53/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,435 - tokenizing ../../103_tei_w/2023-10-23_10-53/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion_01_nlRmd.xml\n",
      "2023-10-23 10:53:37,450 - adding @part on <w>\n",
      "2023-10-23 10:53:37,522 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion_03_tokenized.xml\n",
      "2023-10-23 10:53:37,543 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion_04_posttok.xml\n",
      "2023-10-23 10:53:37,563 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion_04_posttok.xml\n",
      "2023-10-23 10:53:37,594 - No previous annotations found for 12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion\n",
      "2023-10-23 10:53:37,612 - 12_NZ_M.73_Karantina_ManzulDiwanConversationsReligion: done.\n",
      "2023-10-23 10:53:37,613 - \n",
      "\n",
      "*** processing 13_NZ_M.73_Karantina_AnimalmarketFoodpreparation: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_13_NZ_M.73_Karantina_AnimalmarketFoodpreparation.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation.xml\n",
      "2023-10-23 10:53:37,614 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_13_NZ_M.73_Karantina_AnimalmarketFoodpreparation.xml\n",
      "2023-10-23 10:53:37,651 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,662 - removing new lines from ../../103_tei_w/2023-10-23_10-53/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,672 - tokenizing ../../103_tei_w/2023-10-23_10-53/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation_01_nlRmd.xml\n",
      "2023-10-23 10:53:37,689 - adding @part on <w>\n",
      "2023-10-23 10:53:37,759 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation_03_tokenized.xml\n",
      "2023-10-23 10:53:37,785 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation_04_posttok.xml\n",
      "2023-10-23 10:53:37,809 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/13_NZ_M.73_Karantina_AnimalmarketFoodpreparation_04_posttok.xml\n",
      "2023-10-23 10:53:37,855 - No previous annotations found for 13_NZ_M.73_Karantina_AnimalmarketFoodpreparation\n",
      "2023-10-23 10:53:37,889 - 13_NZ_M.73_Karantina_AnimalmarketFoodpreparation: done.\n",
      "2023-10-23 10:53:37,889 - \n",
      "\n",
      "*** processing 02_NZ_M.73_Karantina_BedouinWeddings: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_02_NZ_M.73_Karantina_BedouinWeddings.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/02_NZ_M.73_Karantina_BedouinWeddings.xml\n",
      "2023-10-23 10:53:37,890 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_02_NZ_M.73_Karantina_BedouinWeddings.xml\n",
      "2023-10-23 10:53:37,926 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/02_NZ_M.73_Karantina_BedouinWeddings_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,936 - removing new lines from ../../103_tei_w/2023-10-23_10-53/02_NZ_M.73_Karantina_BedouinWeddings_00_metaMerged.xml\n",
      "2023-10-23 10:53:37,946 - tokenizing ../../103_tei_w/2023-10-23_10-53/02_NZ_M.73_Karantina_BedouinWeddings_01_nlRmd.xml\n",
      "2023-10-23 10:53:37,963 - adding @part on <w>\n",
      "2023-10-23 10:53:38,039 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/02_NZ_M.73_Karantina_BedouinWeddings_03_tokenized.xml\n",
      "2023-10-23 10:53:38,072 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/02_NZ_M.73_Karantina_BedouinWeddings_04_posttok.xml\n",
      "2023-10-23 10:53:38,116 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/02_NZ_M.73_Karantina_BedouinWeddings_04_posttok.xml\n",
      "2023-10-23 10:53:38,175 - No previous annotations found for 02_NZ_M.73_Karantina_BedouinWeddings\n",
      "2023-10-23 10:53:38,201 - 02_NZ_M.73_Karantina_BedouinWeddings: done.\n",
      "2023-10-23 10:53:38,201 - \n",
      "\n",
      "*** processing 11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity.xml\n",
      "2023-10-23 10:53:38,202 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity.xml\n",
      "2023-10-23 10:53:38,247 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity_00_metaMerged.xml\n",
      "2023-10-23 10:53:38,254 - removing new lines from ../../103_tei_w/2023-10-23_10-53/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity_00_metaMerged.xml\n",
      "2023-10-23 10:53:38,264 - tokenizing ../../103_tei_w/2023-10-23_10-53/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity_01_nlRmd.xml\n",
      "2023-10-23 10:53:38,276 - adding @part on <w>\n",
      "2023-10-23 10:53:38,320 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity_03_tokenized.xml\n",
      "2023-10-23 10:53:38,340 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity_04_posttok.xml\n",
      "2023-10-23 10:53:38,359 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity_04_posttok.xml\n",
      "2023-10-23 10:53:38,386 - No previous annotations found for 11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity\n",
      "2023-10-23 10:53:38,405 - 11_NZ_M.73_Karantina_historyKarantina2_TradeLanguageIdentity: done.\n",
      "2023-10-23 10:53:38,406 - \n",
      "\n",
      "*** processing SAU_2022_Speaker14_childhood_womenswork: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker14_childhood_womenswork.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/SAU_2022_Speaker14_childhood_womenswork.xml\n",
      "2023-10-23 10:53:38,406 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_SAU_2022_Speaker14_childhood_womenswork.xml\n",
      "WARNING found several matching recording IDs: SAU_2022_Speaker14_childhood_womenswork, SAU_2022_Speaker14_childhood - taking first one\n",
      "2023-10-23 10:53:38,446 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker14_childhood_womenswork_00_metaMerged.xml\n",
      "2023-10-23 10:53:38,466 - removing new lines from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker14_childhood_womenswork_00_metaMerged.xml\n",
      "2023-10-23 10:53:38,488 - tokenizing ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker14_childhood_womenswork_01_nlRmd.xml\n",
      "2023-10-23 10:53:38,514 - adding @part on <w>\n",
      "2023-10-23 10:53:38,804 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker14_childhood_womenswork_03_tokenized.xml\n",
      "2023-10-23 10:53:38,860 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml\n",
      "2023-10-23 10:53:38,904 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml\n",
      "2023-10-23 10:53:38,958 - No previous annotations found for SAU_2022_Speaker14_childhood_womenswork\n",
      "2023-10-23 10:53:38,998 - SAU_2022_Speaker14_childhood_womenswork: done.\n",
      "2023-10-23 10:53:38,998 - \n",
      "\n",
      "*** processing 07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage: /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage.xml -> /home/dschopper/data/WIBARAB/corpus/103_tei_w/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage.xml\n",
      "2023-10-23 10:53:38,999 - trying to inject metadata from file:///home/dschopper/data/WIBARAB/corpus/103_tei_w/wibarabCorpus.xml into /home/dschopper/data/WIBARAB/corpus/103_tei_w/2023-10-23_10-53/ELAN_07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage.xml\n",
      "2023-10-23 10:53:39,036 - running post-metadata-merge processing on ../../103_tei_w/2023-10-23_10-53/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage_00_metaMerged.xml\n",
      "2023-10-23 10:53:39,043 - removing new lines from ../../103_tei_w/2023-10-23_10-53/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage_00_metaMerged.xml\n",
      "2023-10-23 10:53:39,055 - tokenizing ../../103_tei_w/2023-10-23_10-53/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage_01_nlRmd.xml\n",
      "2023-10-23 10:53:39,070 - adding @part on <w>\n",
      "2023-10-23 10:53:39,123 - applying post-tokenization processing to ../../103_tei_w/2023-10-23_10-53/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage_03_tokenized.xml\n",
      "2023-10-23 10:53:39,149 - creating TEI document for annotation from ../../103_tei_w/2023-10-23_10-53/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage_04_posttok.xml\n",
      "2023-10-23 10:53:39,177 - creating XML vertical from ../../103_tei_w/2023-10-23_10-53/07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage_04_posttok.xml\n",
      "2023-10-23 10:53:39,223 - No previous annotations found for 07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage\n",
      "2023-10-23 10:53:39,256 - 07_NZ_M.73_Karantina_languageUse.NewGeneration.cityVSvillage: done.\n"
     ]
    }
   ],
   "source": [
    "mergeParam = { \"pathToCorpusDoc\": pathlib.Path(os.path.abspath(pathToTeiCorpus)).as_uri() }\n",
    "for doc in ELANDocs:\n",
    "    logging.info(\"\\n\\n*** processing \"+doc[\"basename\"]+': '+doc[\"filepath_tmp_TEI\"]+\" -> \"+doc[\"TEI\"])\n",
    "    \n",
    "    mdMerged = mergeMetadata(doc, mergeParam)\n",
    "    if not mdMerged: \n",
    "        logging.error(\"mergeMetadata did not return expected value. Expected path to merged tmp TEI. returned value: \"+str(mdMerged))\n",
    "    else:\n",
    "        \n",
    "        mdMergedPostProcessed = postProcessMergedTEI(doc, mdMerged)\n",
    "        \n",
    "        if not mdMergedPostProcessed:\n",
    "            logging.error(\"mdMergedPostProcessed did not return expected value. Expected path, got \"+str(mdMergedPostProcessed))\n",
    "        \n",
    "        else:\n",
    "            nlRmved = removeNL(doc, mdMergedPostProcessed)\n",
    "            \n",
    "            if not nlRmved:\n",
    "                logging.error(\"removeNL did not return expected value. Expected path, got \"+str(mdMergedPostProcessed))\n",
    "            else:\n",
    "                \n",
    "                tokenized = tokenize(doc, nlRmved)\n",
    "\n",
    "                if not tokenized:\n",
    "                    logging.error(\"tokenize did not return expected value. Expected path, got \"+str(tokenized))\n",
    "                else:\n",
    "                    pAdded = addP(doc, tokenized)\n",
    "                    if not pAdded:\n",
    "                        logging.error(\"addP did not return expected value. Expected path, got \"+str(pAdded))\n",
    "\n",
    "                    else:\n",
    "                        tokenizedPostProcessed = postProcess(doc, pAdded)\n",
    "                        if not tokenizedPostProcessed:\n",
    "                            logging.error(\"postProcess did not return expected value. Expected path, got \"+str(tokenizedPostProcessed))\n",
    "                        else:\n",
    "                            \n",
    "                            teiForAnnotation = createTEIForAnnotation(doc, tokenizedPostProcessed)\n",
    "                            \n",
    "                            if not teiForAnnotation:\n",
    "                                logging.error(\"createTEIForAnnotation did not return expected value. Expected path, got \"+str(teiForAnnotation))\n",
    "                            \n",
    "                            xmlVert = createXMLVert(doc, tokenizedPostProcessed)\n",
    "                            if not xmlVert:\n",
    "                                logging.error(\"createXMLVert did not return expected value. Expected path, got \"+str(tokenizedPostProcessed))\n",
    "                            \n",
    "                            annotationsAttached = attachAnnotationsToXMLVert(doc, xmlVert)\n",
    "                            if annotationsAttached:\n",
    "                                createNoSkEVert(doc, annotationsAttached)\n",
    "                            else:\n",
    "                                createNoSkEVert(doc, xmlVert)\n",
    "                            \n",
    "                            logging.info(doc[\"basename\"]+\": done.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb522d",
   "metadata": {},
   "source": [
    "## Replace TEI elements with x-includes in corpus document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1045b01-72db-4104-8ebe-e4c4dffa385d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b0b902fac6ad7dd00456e1f7dc72379c0baf1ab5135d56a56b79f9771306c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
