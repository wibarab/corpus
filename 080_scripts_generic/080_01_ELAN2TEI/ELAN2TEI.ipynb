{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34c743a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ELAN to TEI conversion \n",
    "\n",
    "**Author:** Daniel Schopper    \n",
    "**Description:** This notebook automates the ELAN to TEI conversion in the WIBARAB Project. It is based on the same process in the SHAWI Project.\n",
    "**Last Change:** 2023-10-10     \n",
    "**History:**    \n",
    "* 2023-10-10: Initital set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c93b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sharepy\n",
    "import os\n",
    "import logging\n",
    "import requests\n",
    "import pathlib\n",
    "#import filetype â€“ not used\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit\n",
    "import saxonche\n",
    "from zipfile import ZipFile\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "# from inspect import getmembers, signature\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd189fd",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d673ca-740f-4d11-93b7-a9036750f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:34:01,388 - SaxonC-HE 12.3 from Saxonica\n",
      "2023-10-12 12:34:01,394 - Q:\\corpus-data\\080_scripts_generic\n",
      "2023-10-12 12:34:01,395 - ** setting up directories **\n",
      "2023-10-12 12:34:01,396 - created directory 'data'\n",
      "2023-10-12 12:34:01,398 - created directory 'lib'\n"
     ]
    }
   ],
   "source": [
    "# the URL of the Sharepoint installation \n",
    "sp_baseURL = \"oeawacat.sharepoint.com\"\n",
    "\n",
    "# the sharepoint username + password are taken from the environment\n",
    "sp_username = os.environ['SP_USERNAME']\n",
    "sp_pwd = pwd = os.environ['SP_PWD']\n",
    "\n",
    "# the name of the Sharepoint Site\n",
    "sp_siteName = \"ACDH-CH_p_WIBARAB_BedoinTypeArabicNomadicSedentaryPeopleMidd\"\n",
    "\n",
    "# the path to the Excel file\n",
    "sp_pathToRecordingsXLSX = \"Shared%20Documents/Fieldwork%20data%20+%20analysis/WIBARAB_Recordings.xlsx\"\n",
    "\n",
    "\n",
    "# the name of the local directory where downloaded data will be stored\n",
    "dataDir = \"data\"\n",
    "\n",
    "# the name of the local directory where downloaded libraries and other auxiliary code will be stored\n",
    "libDir = \"lib\"\n",
    "\n",
    "# the root of the git repository\n",
    "dataHomeDir = \"../..\"\n",
    "\n",
    "# path to project-specific stylesheets\n",
    "pathToStylesheetsDir = dataHomeDir+\"/082_scripts_xsl\"\n",
    "\n",
    "# the path to the ELAN transcription files\n",
    "pathToELANDir = dataHomeDir+\"/122_elan\"\n",
    "\n",
    "# the path to the non-annotated TEI transcription files\n",
    "pathToTEIDir = dataHomeDir+\"/103_tei_w\"\n",
    "\n",
    "# the path to the annotated TEI transcription files\n",
    "pathToAnnotatedTEIDir = dataHomeDir+\"/010_manannot\"\n",
    "\n",
    "\n",
    "# the path to the NoSkE verticals\n",
    "noSkEVertDir = dataHomeDir+\"/130_vert_plain\"\n",
    "\n",
    "# the path to the tei Corpus document produced by this script\n",
    "pathToTeiCorpus = pathToTEIDir+\"/shawiCorpus.xml\"\n",
    "\n",
    "\n",
    "# the path to the audio files\n",
    "pathToRecordingsDir = \"THIS_IS_NOT_USED\"#\"/mnt/univie_orientalistik/SHAWI/Recordings\"\n",
    "\n",
    "with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "    logging.info(proc.version)\n",
    "    proc.set_cwd(os.path.dirname(os.path.abspath('')))\n",
    "    logging.info(proc.cwd)\n",
    "\n",
    "\n",
    "#set up directories\n",
    "logging.info(\"** setting up directories **\")\n",
    "for i in [dataDir,libDir]: \n",
    "    if os.path.exists(i):\n",
    "        logging.info(\"skipped existing directory '\"+i+\"'\")\n",
    "    else:\n",
    "        os.mkdir(i)\n",
    "        logging.info(\"created directory '\"+i+\"'\")\n",
    "        \n",
    "        \n",
    "# define which steps should be skipped. \n",
    "\n",
    "SKIP_PROCESSING = []#[\"runTEICorpo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda0dc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Step 1: get the latest release of the TEI Stylesheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5960d582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:34:01,407 - ** Fetching library TEIC/TEI **\n",
      "2023-10-12 12:34:45,171 - Downloaded latest version (P5_Release_4.6.0) to lib/TEIC/TEI/P5_Release_4.6.0\n",
      "2023-10-12 12:34:45,172 - \n",
      "2023-10-12 12:34:45,201 - ** Fetching library TEIC/Stylesheets **\n",
      "2023-10-12 12:34:49,177 - Downloaded latest version (v7.55.0) to lib/TEIC/Stylesheets/v7.55.0\n",
      "2023-10-12 12:34:49,178 - \n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "# fetch the TEI Stylesheets    \n",
    "def installFromGithub(libraryName):\n",
    "    auth = {}\n",
    "    if 'GITHUB_TOKEN' in os.environ:\n",
    "        auth = {\"Authorization\": \"Bearer \"+os.environ['GITHUB_TOKEN']}\n",
    "    headers = {\"Accept\" : \"application/vnd.github.v3+json\"}\n",
    "    repo = libraryName\n",
    "    logging.info(\"** Fetching library \"+repo+\" **\")\n",
    "    libBasePath = libDir+\"/\"+repo\n",
    "    \n",
    "    # First we check which tag name the latest release has\n",
    "    r = requests.get(\"https://api.github.com/repos/\"+repo+\"/releases/latest\", headers={**headers, **auth})\n",
    "    if r.status_code != 200:\n",
    "        logging.error(\"An error occured fetching the latest release. Maybe there isn't any release? \")\n",
    "        logging.error(r.content)\n",
    "        return 1\n",
    "    release = r.json()\n",
    "    tag = release[\"tag_name\"]\n",
    "    \n",
    "    # we check whether we have the latest version already \\\n",
    "    # by checking if the respective path is already installed\n",
    "    libReleasePath = libBasePath+\"/\"+tag\n",
    "    haveLatestVersion = os.path.exists(libReleasePath)\n",
    "    if haveLatestVersion:\n",
    "        logging.info(\"We have already the latest version (\"+tag+\"). Exiting\")\n",
    "        logging.info(\"\")\n",
    "        return libReleasePath\n",
    "    else:\n",
    "        url = release[\"assets\"][0][\"browser_download_url\"]\n",
    "        payload = requests.get(url, headers=auth).content\n",
    "        zipfilename = os.path.basename(url)\n",
    "        os.makedirs(libReleasePath, exist_ok=True)\n",
    "        zipfilePath = libReleasePath +\"/\"+zipfilename\n",
    "        open(zipfilePath, 'wb').write(payload)\n",
    "        ZipFile(zipfilePath).extractall(path=libReleasePath)\n",
    "        logging.info(\"Downloaded latest version (\"+tag+\") to \"+libReleasePath)\n",
    "        logging.info(\"\")\n",
    "        return libReleasePath\n",
    "\n",
    "\n",
    "pathToTEIGuidelines=installFromGithub(\"TEIC/TEI\")\n",
    "pathToTEIStylesheets=installFromGithub(\"TEIC/Stylesheets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c41966",
   "metadata": {},
   "source": [
    "### Step 2: Download the latest version of the Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842ce3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:34:49,191 - attempting to download file from 'https://oeawacat.sharepoint.com/sites/ACDH-CH_p_WIBARAB_BedoinTypeArabicNomadicSedentaryPeopleMidd/Shared%20Documents/Fieldwork%20data%20+%20analysis/WIBARAB_Recordings.xlsx'\n",
      "2023-10-12 12:34:54,498 - data/WIBARAB_Recordings.xlsx\n"
     ]
    }
   ],
   "source": [
    "# TODO will need to add credentials if this is run in non-interactive mode\n",
    "def downloadFromSP(sp_filepath, force=False):\n",
    "    url = \"https://\"+sp_baseURL+\"/sites/\"+sp_siteName+\"/\"+sp_filepath\n",
    "    logging.info(\"attempting to download file from '\"+url+\"'\")\n",
    "    filename = os.path.basename(sp_filepath)\n",
    "    downloadPath = dataDir+\"/\"+filename\n",
    "    if os.path.exists(downloadPath) and not force:\n",
    "        logging.info(\"skipping existing file \"+downloadPath)\n",
    "        return downloadPath\n",
    "    else:\n",
    "        s = sharepy.connect(sp_baseURL, username=sp_username, password=sp_pwd)\n",
    "        s.getfile(url, filename=downloadPath)\n",
    "        if os.path.exists(downloadPath):\n",
    "            return downloadPath\n",
    "        else:\n",
    "            print(\"an error occured\")\n",
    "            print(s)\n",
    "\n",
    "\n",
    "pathToExcelSheet = downloadFromSP(sp_pathToRecordingsXLSX, force=\"downloadExcelSheet\" not in SKIP_PROCESSING)\n",
    "logging.info(pathToExcelSheet)\n",
    "#print(\"download ok? \"+str(os.path.exists(pathToExcelSheet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9687813",
   "metadata": {},
   "source": [
    "## Step 2: transform xlsx to TEI table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c1a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(s, xsl, o, parameters=[]):\n",
    "    # processor keeps files open on Windows and in doing so prevents moving or copying them\n",
    "    with saxonche.PySaxonProcessor(license=False) as proc:\n",
    "        proc.set_configuration_property(\"xi\", \"on\")\n",
    "        saxon = proc.new_xslt30_processor()\n",
    "        for i in parameters:\n",
    "            saxon.set_parameter(name=i, value=proc.make_string_value(parameters[i]))\n",
    "        try:\n",
    "            exec = saxon.compile_stylesheet(stylesheet_file=os.path.abspath(xsl))\n",
    "            exec.set_global_context_item(file_name=os.path.abspath(s))\n",
    "            # From the docs saxonc.html#PyXsltExecutable-set_initial_match_selection\n",
    "            # This method does not set the global context item for the transformation;\n",
    "            # if that is required, it can be done separately using the set_global_context_item method.\n",
    "            exec.apply_templates_returning_file(source_file=os.path.abspath(s), output_file=os.path.abspath(o))\n",
    "        except saxonche.PySaxonApiError as e:\n",
    "            logging.info(str(e))\n",
    "            logging.info(os.path.abspath(s)+\" - \"+os.path.abspath(xsl)+\" -> \"+os.path.abspath(o)+\" failed\")\n",
    "        if proc.exception_occurred:\n",
    "            logging.info(proc.get_error_message())\n",
    "            logging.info(os.path.abspath(s)+\" - \"+os.path.abspath(xsl)+\" -> \"+os.path.abspath(o)+\" failed\")\n",
    "        if os.path.exists(os.path.abspath(o)):\n",
    "            return o\n",
    "        else: \n",
    "            logging.info(\"there was an error transforming \"+s+\" with stylesheet \"+xsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531fda65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xlsx2teitable(xlsx, output):\n",
    "\n",
    "    # first, extract contents of XLSX document to a temp directory\n",
    "    unzipPath=xlsx.replace(\".xlsx\",\"\")\n",
    "    os.makedirs(unzipPath, exist_ok=True)\n",
    "    ZipFile(xlsx).extractall(path=unzipPath)\n",
    "    \n",
    "    # then transform the .rels file using the TEIC Stylesheets \n",
    "    pathToXlsxtoteiXSL=pathToTEIStylesheets+\"/xml/tei/stylesheet/xlsx/xlsxtotei.xsl\"\n",
    "\n",
    "    params = {\n",
    "        \"inputDir\" : pathlib.Path(os.path.abspath(unzipPath)).as_uri(),\n",
    "        \"workDir\" : pathlib.Path(os.path.abspath(unzipPath)).as_uri()\n",
    "        \n",
    "    }\n",
    "\n",
    "    transform(\n",
    "        s = unzipPath+\"/_rels/.rels\", \n",
    "        xsl = pathToXlsxtoteiXSL, \n",
    "        o = output, \n",
    "        parameters=params\n",
    "    )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e041e152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:36:55,331 - data/WIBARAB_Recordings.xml\n"
     ]
    }
   ],
   "source": [
    "pathToTEItable=pathToExcelSheet.replace(\".xlsx\",\".xml\")\n",
    "\n",
    "if not \"xlsx2teitable\" in SKIP_PROCESSING:    \n",
    "    xlsx2teitable(xlsx=pathToExcelSheet, output=pathToTEItable)\n",
    "    debugstring=\"\"\"<!-- \n",
    "   THIS FILE IS INCLUDED IN THE GIT REPOSITORY ONLY FOR DEBUGGING PURPOSES. \n",
    "   \n",
    "   The source of this file is constantly being edited at \n",
    "   https://oeawacat.sharepoint.com/sites/ACDH-CH_p_ShawiTypeArabicDialects_Shawi/_layouts/15/Doc.aspx?sourcedoc={F01FF43B-2409-4E31-A5BF-653E0559B160}&file=SHAWI%20Recordings.xlsx&action=default&mobileredirect=true&cid=f7311564-c2b6-4b08-9a52-468547688408\n",
    "   So this copy is most probably already outdated.\n",
    "   \n",
    "  To update it, you can either run https://gitlab.com/acdh-oeaw/shawibarab/shawi-data/-/blob/main/080_scripts_generic/080_01_ELAN2TEI/ELAN2TEI.ipyn\n",
    "   *OR*  \n",
    "   1) download the Excel file manually from Sharepoint\n",
    "   2) and tranform it to TEI using oxgarage.tei-c.org/ \n",
    "   \n",
    "-->\n",
    "    \"\"\"\n",
    "    f = open(pathToTEItable,mode=\"r\",encoding=\"UTF8\")\n",
    "    src = f.read()\n",
    "    new = src.replace('<?xml version=\"1.0\" encoding=\"UTF-8\"?>','<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'+debugstring)\n",
    "    f.close()\n",
    "    f = open(pathToTEItable, mode=\"wt\",encoding=\"UTF8\")\n",
    "    f.write(new)\n",
    "    f.close()\n",
    "        \n",
    "    logging.info(pathToTEItable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca2fcd",
   "metadata": {},
   "source": [
    "## Step 3: transform TEI table to corpus header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0889b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:37:00,690 - ../../103_tei_w/shawiCorpus.xml\n"
     ]
    }
   ],
   "source": [
    "pathToTeitableToCorpusXSL=pathToStylesheetsDir+\"/table2corpus.xsl\"\n",
    "params = {\n",
    "    \"pathToRecordings\" : pathlib.Path(os.path.abspath(pathToRecordingsDir)).as_uri()\n",
    "}\n",
    "try:\n",
    "    transform(pathToTEItable, pathToTeitableToCorpusXSL, pathToTeiCorpus, params)\n",
    "except saxonche.PySaxonApiError as e:\n",
    "    logging.error(\"an error occured: \" + str(e) + \"\\n\" + pathToTEItable + \": \" + pathToTeitableToCorpusXSL + \" -> \" + pathToTeiCorpus)\n",
    "logging.info(pathToTeiCorpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd00c7",
   "metadata": {},
   "source": [
    "## Step 4: Run TEICorpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8914cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:37:06,427 - file lib/teicorpo.jar downloaded\n",
      "2023-10-12 12:37:07,477 - file lib/commons-io-2.11.0.jar downloaded\n",
      "2023-10-12 12:37:07,480 - lib/*\n"
     ]
    }
   ],
   "source": [
    "def installFromUrl(url, force=False):\n",
    "    r = requests.get(url)\n",
    "    filename = os.path.basename(urlsplit(url).path)\n",
    "    downloadpath = libDir+\"/\"+filename\n",
    "    if os.path.exists(downloadpath) and not force:\n",
    "        logging.info(\"skipping download\")\n",
    "    else:\n",
    "        open(downloadpath, 'wb').write(r.content)\n",
    "        logging.info(\"file \"+downloadpath+\" downloaded\")\n",
    "    return downloadpath\n",
    "\n",
    "# TODO check for filetype and automatically extract zip file \n",
    "# so this can be re-used for the insta\n",
    " \n",
    "installFromUrl(\"https://github.com/christopheparisse/teicorpo/blob/e06a01ad5cb4c3aef631b3749ce59b5eb6f5ea11/teicorpo.jar?raw=true\")\n",
    "installFromUrl(\"https://repo1.maven.org/maven2/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar\")\n",
    "pathToTeiCorpo=libDir+\"/*\"\n",
    "logging.info(pathToTeiCorpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68193a14",
   "metadata": {},
   "source": [
    "Collect all ELAN documents from pathToELANDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc55161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:37:13,540 - Q:\\corpus-data\\122_elan\\SAU_2022_Speaker10_marriage.eaf\n",
      "2023-10-12 12:37:13,541 - Q:\\corpus-data\\122_elan\\SAU_2022_Speaker14_childhood_womenswork.eaf\n",
      "2023-10-12 12:37:13,541 - Q:\\corpus-data\\122_elan\\SAU_2022_Speaker20_shepherd.eaf\n",
      "2023-10-12 12:37:13,542 - Q:\\corpus-data\\122_elan\\SAU_2022_Speaker20_traditionaltools.eaf\n"
     ]
    }
   ],
   "source": [
    "ELANDocs = []\n",
    "\n",
    "for i in os.scandir(pathToELANDir):\n",
    "    filename=os.path.basename(i)\n",
    "    if filename.endswith(\".eaf\"):\n",
    "        basename=Path(i).stem\n",
    "        ELANDocs.append({\n",
    "            \"filepath\" : os.path.abspath(i),\n",
    "            \"filename\" : filename,\n",
    "            \"basename\" : basename\n",
    "        })\n",
    "        \n",
    "        # check whether there is already a manually annotated TEI version of this ELAN document\n",
    "        TEI_annotated_filename=pathToAnnotatedTEIDir+\"/\"+basename+\".xml\"\n",
    "        \n",
    "        ELANDocs[-1][\"TEI_annotated\"]=os.path.abspath(TEI_annotated_filename)\n",
    "for d in ELANDocs:\n",
    "    logging.info(d[\"filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec70e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTEICorpo(docs = dict):\n",
    "    runtime = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    tmpDir = pathToTEIDir+\"/\"+runtime\n",
    "    os.makedirs(tmpDir, exist_ok=True)\n",
    "    for i in docs:\n",
    "        pathToInput = i[\"filepath\"]\n",
    "        filenameELAN = i[\"filename\"]\n",
    "        filenameTEI = i[\"basename\"]+\".xml\"\n",
    "        pathToOutput = tmpDir+\"/\"+\"ELAN_\"+filenameTEI\n",
    "        i[\"filepath_tmp_TEI\"] = os.path.abspath(pathToOutput)\n",
    "        i[\"tmpDir\"] = tmpDir\n",
    "        output = os.path.abspath(pathToTEIDir + \"/\" + i[\"basename\"] + \".xml\")\n",
    "        i[\"TEI\"] = os.path.abspath(output)\n",
    "        res = subprocess.run([\"java\", \"-cp\", pathToTeiCorpo, \"-Dfile.encoding=UTF-8\", \"fr.ortolang.teicorpo.TeiCorpo\", \"-from\",\"elan\", \"-to\",\"tei\", \"-o\",pathToOutput, pathToInput], capture_output=True, encoding=\"UTF-8\")\n",
    "        print(res.stdout)\n",
    "        print(res.stderr)\n",
    "        print(pathToOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38413b21",
   "metadata": {},
   "source": [
    "run TEI Corpo on all ELANDocs, writing the path to the TEI output back to the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2862351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF8\n",
      "\n",
      "../../103_tei_w/2023-10-12_12-37/ELAN_SAU_2022_Speaker10_marriage.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF8\n",
      "\n",
      "../../103_tei_w/2023-10-12_12-37/ELAN_SAU_2022_Speaker14_childhood_womenswork.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF8\n",
      "\n",
      "../../103_tei_w/2023-10-12_12-37/ELAN_SAU_2022_Speaker20_shepherd.xml\n",
      "TeiCorpo (version 1.4.44) 14/12/2021 08:07 Version TEI_CORPO: 0.9.1\n",
      "\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF8\n",
      "\n",
      "../../103_tei_w/2023-10-12_12-37/ELAN_SAU_2022_Speaker20_traditionaltools.xml\n"
     ]
    }
   ],
   "source": [
    "if not \"runTEICorpo\" in SKIP_PROCESSING:\n",
    "    runTEICorpo(docs=ELANDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51dc1f",
   "metadata": {},
   "source": [
    "## Step 5: Merge metadata and TEICorpo Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a40c251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mergeMetadata(docInfo, p):\n",
    "    return transform(\n",
    "        s = docInfo[\"filepath_tmp_TEI\"],\n",
    "        xsl = pathToStylesheetsDir+\"/mergeHeaderAndTranscription.xsl\",\n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_00_metaMerged.xml\",\n",
    "        parameters = p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a7c29-d7bb-47c7-ba8b-d1073168d67d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 6: Tokenization of unannotated texts\n",
    "\n",
    "Run a local copy of [xsl-tokenizer](https://github.com/acdh-oeaw/xsl-tokenizer)\n",
    "\n",
    "The merged TEI document is tokenized for further manual annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302385d4-f8b0-4f9c-bdfa-75a645e884f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6.0: (Re-)generate tokenizer stylesheets (optional)\n",
    "\n",
    "Regenerate the XSLs used in the following steps.\n",
    "This can not be done with saxonpy (xincludes are not resolved)\n",
    "use\n",
    "```bash\n",
    "java -jar Saxon-HE-9.9.1-8.jar -s:profile.xml -xi:on -xsl:xsl/make_xsl.xsl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b9698-1946-4114-ba8b-5d2caca7b7f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "For all the ELAN files converted to TEI:\n",
    "\n",
    "### Step 6.1: Remove new lines\n",
    "\n",
    "Remove new lines and store to intermediate document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb48707-d990-4737-8115-277497add47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNL(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_00_metaMerged.xml\", \n",
    "        xsl = \"./tokenizer/xsl/rmNl.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_01_nlRmd.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95efdd-eaaa-4132-a42b-e70f6a0225b5",
   "metadata": {},
   "source": [
    "### Step 6.2: create w tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a825ea8-f03d-4f56-b4ef-158817e5cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_01_nlRmd.xml\", \n",
    "        xsl = \"./tokenizer/wrapper_toks.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_02_toks.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33998805-c4f2-4039-999b-419acb3e69f9",
   "metadata": {},
   "source": [
    "### Step 6.3: Add part attributes to w tags\n",
    "\n",
    "Add Part-Attributes and explicit token links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3946396-3a73-4180-873f-2361a669cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addP(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_02_toks.xml\", \n",
    "        xsl = \"./tokenizer/wrapper_addP.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_03_tokenized.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729253b-f6e2-42b8-b4ef-e67319aed15b",
   "metadata": {},
   "source": [
    "### Step 6.4: apply project-specific post-processing\n",
    "\n",
    "Do some post tokenization processing specific to the Shawi project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6292bd18-6718-4d64-97c7-c4c093283f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcess(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_03_tokenized.xml\", \n",
    "        xsl = \"./tokenizer/postTokenization/1.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e721c-bb9e-4a7b-b6fd-be53e06b14b3",
   "metadata": {},
   "source": [
    "## Step 6.5: move token namespace from xtoks to TEI \n",
    "\n",
    "**--> This step creates the files which data curators will copy to `010_manannot` and annotate using the TEI enricher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44f2ec8a-fe7e-4142-9382-b5cd3bfd30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTEIForAnnotation(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\",\n",
    "        xsl = \"./tokenizer/custom_xtoks2tei.xsl\", \n",
    "        o = docInfo[\"TEI\"],\n",
    "        parameters = {\n",
    "            \"preserve-ws\": \"false\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44acba-435d-449c-afc1-1288233036e1",
   "metadata": {},
   "source": [
    "## Step 7: Create NoSke input\n",
    "\n",
    "We create verticals from the unannotated texts and attach the token annotations from `010_manannot` to them.\n",
    "\n",
    "### Step 7.1 Create XML vertical from tokenized XML documents\n",
    "\n",
    "We take the tokenized XML document (prior to have moved to TEI) and create an XML vertical from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e07285-908a-4f6e-89ff-43b4f59e103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXMLVert(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_04_posttok.xml\",\n",
    "        xsl = \"./tokenizer/custom_xtoks2vert.xsl\", \n",
    "        o = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_05_vert.xml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29a7e0-e42c-4e87-a443-17501b1191cc",
   "metadata": {},
   "source": [
    "### Step 7.2: attach manual annotations to the XML vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01c0cfa1-cba3-4480-b040-94749902527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attachAnnotationsToXMLVert(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"]+'/'+docInfo[\"basename\"]+\"_05_vert.xml\",\n",
    "        xsl = pathToStylesheetsDir+\"/copyAnaToVert.xsl\", \n",
    "        o = docInfo[\"tmpDir\"] + \"/\" + docInfo[\"basename\"] + \"_05_vert_annot.xml\",\n",
    "        parameters = {\n",
    "            \"path_to_annotated_doc\": pathlib.Path(os.path.abspath(docInfo[\"TEI_annotated\"])).as_uri()\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107ed8f-dfa4-41b8-9f24-c63a9c71589c",
   "metadata": {},
   "source": [
    "### Step 7.3 convert XML vertical to text vertical\n",
    "\n",
    "Create a vertical vor NoSkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed763150-c07c-45d0-b077-05f8839e3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNoSkEVert(docInfo):\n",
    "    return transform(\n",
    "        s = docInfo[\"tmpDir\"] + \"/\" + docInfo[\"basename\"] + \"_05_vert_annot.xml\",\n",
    "        xsl = \"./tokenizer/wrapper_vert2txt.xsl\", \n",
    "        o = noSkEVertDir + \"/\" + docInfo[\"basename\"] + \".txt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b488db-49d5-4f4b-a81c-f4e2dbf712d0",
   "metadata": {},
   "source": [
    "## Run Steps 6- 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f24c432-2ac1-48d8-a50f-604b34b808d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:37:43,325 - XTMM9000: Processing terminated by xsl:message at line 34 in mergeHeaderAndTranscription.xsl. Line number: 34\n",
      "2023-10-12 12:37:43,326 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\ELAN_SAU_2022_Speaker10_marriage.xml - Q:\\corpus-data\\082_scripts_xsl\\mergeHeaderAndTranscription.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_00_metaMerged.xml failed\n",
      "2023-10-12 12:37:43,331 - org.xml.sax.SAXParseException; systemId: file:///Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_00_metaMerged.xml; lineNumber: 1; columnNumber: 1; Premature end of file.. Line number: -1\n",
      "2023-10-12 12:37:43,332 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_00_metaMerged.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\xsl\\rmNl.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_01_nlRmd.xml failed\n",
      "2023-10-12 12:37:43,332 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_00_metaMerged.xml with stylesheet ./tokenizer/xsl/rmNl.xsl\n",
      "2023-10-12 12:37:43,339 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_01_nlRmd.xml. Line number: -1\n",
      "2023-10-12 12:37:43,340 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_01_nlRmd.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\wrapper_toks.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_02_toks.xml failed\n",
      "2023-10-12 12:37:43,341 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_01_nlRmd.xml with stylesheet ./tokenizer/wrapper_toks.xsl\n",
      "2023-10-12 12:37:43,350 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_02_toks.xml. Line number: -1\n",
      "2023-10-12 12:37:43,352 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_02_toks.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\wrapper_addP.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_03_tokenized.xml failed\n",
      "2023-10-12 12:37:43,353 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_02_toks.xml with stylesheet ./tokenizer/wrapper_addP.xsl\n",
      "2023-10-12 12:37:43,358 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_03_tokenized.xml. Line number: -1\n",
      "2023-10-12 12:37:43,360 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_03_tokenized.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\postTokenization\\1.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_04_posttok.xml failed\n",
      "2023-10-12 12:37:43,360 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_03_tokenized.xml with stylesheet ./tokenizer/postTokenization/1.xsl\n",
      "2023-10-12 12:37:43,383 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_04_posttok.xml. Line number: -1\n",
      "2023-10-12 12:37:43,384 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_04_posttok.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\custom_xtoks2tei.xsl -> Q:\\corpus-data\\103_tei_w\\SAU_2022_Speaker10_marriage.xml failed\n",
      "2023-10-12 12:37:43,384 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_04_posttok.xml with stylesheet ./tokenizer/custom_xtoks2tei.xsl\n",
      "2023-10-12 12:37:43,392 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_04_posttok.xml. Line number: -1\n",
      "2023-10-12 12:37:43,393 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_04_posttok.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\custom_xtoks2vert.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_05_vert.xml failed\n",
      "2023-10-12 12:37:43,394 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_04_posttok.xml with stylesheet ./tokenizer/custom_xtoks2vert.xsl\n",
      "2023-10-12 12:37:43,398 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_05_vert.xml. Line number: -1\n",
      "2023-10-12 12:37:43,399 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_05_vert.xml - Q:\\corpus-data\\082_scripts_xsl\\copyAnaToVert.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_05_vert_annot.xml failed\n",
      "2023-10-12 12:37:43,400 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_05_vert.xml with stylesheet ../../082_scripts_xsl/copyAnaToVert.xsl\n",
      "2023-10-12 12:37:43,407 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_05_vert_annot.xml. Line number: -1\n",
      "2023-10-12 12:37:43,408 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker10_marriage_05_vert_annot.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\wrapper_vert2txt.xsl -> Q:\\corpus-data\\130_vert_plain\\SAU_2022_Speaker10_marriage.txt failed\n",
      "2023-10-12 12:37:43,409 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker10_marriage_05_vert_annot.xml with stylesheet ./tokenizer/wrapper_vert2txt.xsl\n",
      "2023-10-12 12:37:43,437 - XPTY0004: A sequence of more than one item is not allowed as the first argument of fn:normalize-space() (\"SAU_2022_Speaker14_childhood_womenswork\", \"SAU_2022_Speaker14_childhood\") . Line number: 29\n",
      "2023-10-12 12:37:43,438 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\ELAN_SAU_2022_Speaker14_childhood_womenswork.xml - Q:\\corpus-data\\082_scripts_xsl\\mergeHeaderAndTranscription.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_00_metaMerged.xml failed\n",
      "2023-10-12 12:37:43,442 - org.xml.sax.SAXParseException; systemId: file:///Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_00_metaMerged.xml; lineNumber: 1; columnNumber: 1; Premature end of file.. Line number: -1\n",
      "2023-10-12 12:37:43,443 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_00_metaMerged.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\xsl\\rmNl.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_01_nlRmd.xml failed\n",
      "2023-10-12 12:37:43,444 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_00_metaMerged.xml with stylesheet ./tokenizer/xsl/rmNl.xsl\n",
      "2023-10-12 12:37:43,450 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_01_nlRmd.xml. Line number: -1\n",
      "2023-10-12 12:37:43,451 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_01_nlRmd.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\wrapper_toks.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_02_toks.xml failed\n",
      "2023-10-12 12:37:43,452 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_01_nlRmd.xml with stylesheet ./tokenizer/wrapper_toks.xsl\n",
      "2023-10-12 12:37:43,461 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_02_toks.xml. Line number: -1\n",
      "2023-10-12 12:37:43,461 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_02_toks.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\wrapper_addP.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_03_tokenized.xml failed\n",
      "2023-10-12 12:37:43,462 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_02_toks.xml with stylesheet ./tokenizer/wrapper_addP.xsl\n",
      "2023-10-12 12:37:43,467 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_03_tokenized.xml. Line number: -1\n",
      "2023-10-12 12:37:43,468 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_03_tokenized.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\postTokenization\\1.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml failed\n",
      "2023-10-12 12:37:43,469 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_03_tokenized.xml with stylesheet ./tokenizer/postTokenization/1.xsl\n",
      "2023-10-12 12:37:43,473 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml. Line number: -1\n",
      "2023-10-12 12:37:43,475 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\custom_xtoks2tei.xsl -> Q:\\corpus-data\\103_tei_w\\SAU_2022_Speaker14_childhood_womenswork.xml failed\n",
      "2023-10-12 12:37:43,476 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml with stylesheet ./tokenizer/custom_xtoks2tei.xsl\n",
      "2023-10-12 12:37:43,482 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml. Line number: -1\n",
      "2023-10-12 12:37:43,491 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\custom_xtoks2vert.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_05_vert.xml failed\n",
      "2023-10-12 12:37:43,497 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_04_posttok.xml with stylesheet ./tokenizer/custom_xtoks2vert.xsl\n",
      "2023-10-12 12:37:43,500 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_05_vert.xml. Line number: -1\n",
      "2023-10-12 12:37:43,501 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_05_vert.xml - Q:\\corpus-data\\082_scripts_xsl\\copyAnaToVert.xsl -> Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_05_vert_annot.xml failed\n",
      "2023-10-12 12:37:43,502 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_05_vert.xml with stylesheet ../../082_scripts_xsl/copyAnaToVert.xsl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\\corpus-data\\103_tei_w\\shawiCorpus.xml\n",
      "SAU_2022_Speaker10_marriage: Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\ELAN_SAU_2022_Speaker10_marriage.xml -> Q:\\corpus-data\\103_tei_w\\SAU_2022_Speaker10_marriage.xml\n",
      "SAU_2022_Speaker10_marriage: done.\n",
      "SAU_2022_Speaker14_childhood_womenswork: Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\ELAN_SAU_2022_Speaker14_childhood_womenswork.xml -> Q:\\corpus-data\\103_tei_w\\SAU_2022_Speaker14_childhood_womenswork.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:37:43,509 - I/O error reported by XML parser processing /Q:/corpus-data/103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_05_vert_annot.xml. Line number: -1\n",
      "2023-10-12 12:37:43,510 - Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\SAU_2022_Speaker14_childhood_womenswork_05_vert_annot.xml - Q:\\corpus-data\\080_scripts_generic\\080_01_ELAN2TEI\\tokenizer\\wrapper_vert2txt.xsl -> Q:\\corpus-data\\130_vert_plain\\SAU_2022_Speaker14_childhood_womenswork.txt failed\n",
      "2023-10-12 12:37:43,511 - there was an error transforming ../../103_tei_w/2023-10-12_12-37/SAU_2022_Speaker14_childhood_womenswork_05_vert_annot.xml with stylesheet ./tokenizer/wrapper_vert2txt.xsl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAU_2022_Speaker14_childhood_womenswork: done.\n",
      "SAU_2022_Speaker20_shepherd: Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\ELAN_SAU_2022_Speaker20_shepherd.xml -> Q:\\corpus-data\\103_tei_w\\SAU_2022_Speaker20_shepherd.xml\n",
      "SAU_2022_Speaker20_shepherd: done.\n",
      "SAU_2022_Speaker20_traditionaltools: Q:\\corpus-data\\103_tei_w\\2023-10-12_12-37\\ELAN_SAU_2022_Speaker20_traditionaltools.xml -> Q:\\corpus-data\\103_tei_w\\SAU_2022_Speaker20_traditionaltools.xml\n",
      "SAU_2022_Speaker20_traditionaltools: done.\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(pathToTeiCorpus))\n",
    "mergeParam = { \"pathToCorpusDoc\": pathlib.Path(os.path.abspath(pathToTeiCorpus)).as_uri() }\n",
    "for doc in ELANDocs:\n",
    "    print(doc[\"basename\"]+': '+doc[\"filepath_tmp_TEI\"]+\" -> \"+doc[\"TEI\"])\n",
    "    mergeMetadata(doc, mergeParam)\n",
    "    removeNL(doc)\n",
    "    tokenize(doc)\n",
    "    addP(doc)\n",
    "    postProcess(doc)\n",
    "    createTEIForAnnotation(doc)\n",
    "    createXMLVert(doc)\n",
    "    attachAnnotationsToXMLVert(doc)\n",
    "    createNoSkEVert(doc)\n",
    "    print(doc[\"basename\"]+\": done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb522d",
   "metadata": {},
   "source": [
    "## Replace TEI elements with x-includes in corpus document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1045b01-72db-4104-8ebe-e4c4dffa385d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b0b902fac6ad7dd00456e1f7dc72379c0baf1ab5135d56a56b79f9771306c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
